1
00:00:01,000 --> 00:00:02,060
Greetings everyone.

2
00:00:02,060 --> 00:00:08,340
In this video I am going to show you how you can inject your subject, in this case my face,

3
00:00:08,340 --> 00:00:13,200
into any custom model by using Automatic1111 Web UI.

4
00:00:13,200 --> 00:00:17,900
So you see, the center image is my original
image and the other images are generated by

5
00:00:17,900 --> 00:00:22,609
using this injected model, which is Protegen x3.4.

6
00:00:22,609 --> 00:00:26,320
It's an awesome model to generate hyperrealistic pictures.

7
00:00:26,320 --> 00:00:28,890
This is the official site.

8
00:00:28,890 --> 00:00:33,140
So if you don't know how to use Automatic1111, I have great tutorials.

9
00:00:33,140 --> 00:00:40,250
First of all, I have shown how to install Automatic 1111 and run it in this video.

10
00:00:40,250 --> 00:00:45,730
And I have shown how to use different models
with Automatic1111 in this video.

11
00:00:45,730 --> 00:00:51,460
And recently my published video shows how
you can train your subject, e.g. your face

12
00:00:51,460 --> 00:00:56,410
or anything, by using Automatic 1111 and DreamBooth extension.

13
00:00:56,410 --> 00:01:01,329
And if your graphic card is not very good but can support LoRA training, then I have

14
00:01:01,329 --> 00:01:04,589
shown how to do LoRA training in this video.

15
00:01:04,589 --> 00:01:11,540
Even though if you are still not able to train
your subject by using LoRA, if you still don't

16
00:01:11,540 --> 00:01:14,430
have a decent graphic card, then don't worry.

17
00:01:14,430 --> 00:01:20,810
I have shown how to use Google Colab to teach
your subject and then you can generate ckpt

18
00:01:20,810 --> 00:01:26,360
file on Google Colab, download it and can
use it on Automatic1111 web UI.

19
00:01:26,360 --> 00:01:31,730
And in this video I have shown how to use
custom models on Google Colab for training.

20
00:01:31,730 --> 00:01:33,220
Now we can start.

21
00:01:33,220 --> 00:01:36,979
By the way, I will put all of these videos
links into the description and they are all

22
00:01:36,979 --> 00:01:38,259
available in our channel.

23
00:01:38,259 --> 00:01:42,990
Go to our channel main page and in here you
will see Stable Diffusion DreamBooth playlist

24
00:01:42,990 --> 00:01:45,810
and everything is available here.

25
00:01:45,810 --> 00:01:48,090
I will also put the link of this to the description.

26
00:01:48,090 --> 00:01:49,890
OK, now we can start.

27
00:01:49,890 --> 00:01:57,189
So currently the selected model is my trained
model in the my last video.

28
00:01:57,189 --> 00:02:00,479
I have trained my face by using 12 images.

29
00:02:00,479 --> 00:02:03,340
So this is the training data set.

30
00:02:03,340 --> 00:02:09,500
If you wonder what kind of data set was was
used, it's a pretty simple and small data

31
00:02:09,500 --> 00:02:12,819
set: only 12 images.

32
00:02:12,819 --> 00:02:16,550
OK, this is the image that the training model
can generate.

33
00:02:16,550 --> 00:02:21,920
By the way, the training model is based on
SD 1.5 official version.

34
00:02:21,920 --> 00:02:25,120
You see, it is a pretty bad quality actually.

35
00:02:25,120 --> 00:02:31,630
So to get very good, very high quality images
on the default SD 1.5 version data set, you

36
00:02:31,630 --> 00:02:38,240
have to generate insane amount of images and
you have to do a lot of prompt trying.

37
00:02:38,240 --> 00:02:43,870
So you see, this is a pretty simple prompt
actually, and this is also a pretty simple

38
00:02:43,870 --> 00:02:45,209
negative prompt.

39
00:02:45,209 --> 00:02:52,319
So how are we going to inject our trained
model into a custom model.

40
00:02:52,319 --> 00:02:57,530
First of all, as a primary model, we are going
to select the target model, which is Protegen

41
00:02:57,530 --> 00:03:00,860
x3.4 in this case.

42
00:03:00,860 --> 00:03:03,970
A photo realism model, a very high quality
model.

43
00:03:03,970 --> 00:03:10,560
I have selected it from this drop down box:
Protegen x3.4, official.

44
00:03:10,560 --> 00:03:18,330
Then the secondary model will be the model
that we will extract our trained subject,

45
00:03:18,330 --> 00:03:23,530
which is web ui ohwx, my face trained model.

46
00:03:23,530 --> 00:03:27,430
OK, let me select it.

47
00:03:27,430 --> 00:03:28,540
And the tertiary model.

48
00:03:28,540 --> 00:03:30,890
So what is tertiary model?

49
00:03:30,890 --> 00:03:37,799
The strategy we are going to use is like this:
So the base model, which is the tertiary model,

50
00:03:37,799 --> 00:03:38,799
C model.

51
00:03:38,799 --> 00:03:43,849
In the base model, we are going to select
the base model that we used to train our subject,

52
00:03:43,849 --> 00:03:48,210
which is version 1.5 Pruned ckpt.

53
00:03:48,210 --> 00:03:53,659
And the trained model is model B, which is
Web UI owhx, and the target model is model

54
00:03:53,659 --> 00:04:02,349
A. So what we are going to do is we are going
to subtract model C from model B. And what

55
00:04:02,349 --> 00:04:04,130
will be left?

56
00:04:04,130 --> 00:04:06,890
Only our trained subject will be left.

57
00:04:06,890 --> 00:04:14,120
OK, because we have trained our subject, in
my case my face, and we have now the trained

58
00:04:14,120 --> 00:04:19,548
model have my face and the rest is supposed
to be same with the base model.

59
00:04:19,548 --> 00:04:25,900
And then we are going to inject our face into
our target model, which is Protegen.

60
00:04:25,900 --> 00:04:27,720
So how are we going to do that?

61
00:04:27,720 --> 00:04:29,600
First of all, we need to define a custom name.

62
00:04:29,600 --> 00:04:35,690
I will say my face, Protegen, like this: So
multiplier.

63
00:04:35,690 --> 00:04:38,970
What kind of model we want to get?

64
00:04:38,970 --> 00:04:43,210
This is defining the strength of our injection.

65
00:04:43,210 --> 00:04:50,020
For faces the community suggests 75 percent,
which is equal to zero point seventy five.

66
00:04:50,020 --> 00:04:56,910
I have, I have made a lot of tests and I seen
that for my particular trained model, 95 percent

67
00:04:56,910 --> 00:04:58,770
is working better.

68
00:04:58,770 --> 00:05:01,960
Then you are selecting add difference here,
not the weighted sum.

69
00:05:01,960 --> 00:05:08,220
We are going to use add selected add difference,
because this is the strategy that we are going

70
00:05:08,220 --> 00:05:11,130
to use and generate ckpt.

71
00:05:11,130 --> 00:05:15,759
You don't need to save as float16 Just click
run.

72
00:05:15,759 --> 00:05:17,069
OK.

73
00:05:17,069 --> 00:05:22,300
In the CMD window you will see that it is
loading the models then generating the target

74
00:05:22,300 --> 00:05:26,640
model, like this: My face protogen ckpt and
the checkpoint saved.

75
00:05:26,640 --> 00:05:32,270
Now let's go back to text image tab and click
refresh.

76
00:05:32,270 --> 00:05:36,380
And now we can see my face protogen ckpt.

77
00:05:36,380 --> 00:05:38,050
OK.

78
00:05:38,050 --> 00:05:42,020
Now let's generate an image to see what kind
of quality we are going to get.

79
00:05:42,020 --> 00:05:45,050
OK, this is the quality we got.

80
00:05:45,050 --> 00:05:50,770
With just a try you can generate hundreds
of images and generate much higher quality

81
00:05:50,770 --> 00:05:51,770
images.

82
00:05:51,770 --> 00:05:56,569
The eye color is not matching, therefore I
should add also brown eyes here.

83
00:05:56,569 --> 00:05:59,009
But there are several key issues.

84
00:05:59,009 --> 00:06:06,750
The first key issue is that how did I come
up with this prompt strength 1.4 and how did

85
00:06:06,750 --> 00:06:09,349
I picked The CFG value?

86
00:06:09,349 --> 00:06:10,349
To do that.

87
00:06:10,349 --> 00:06:11,349
It is very easy.

88
00:06:11,349 --> 00:06:18,229
First of all, let's define a weight here,
weight_val, like this as you can see: OK,

89
00:06:18,229 --> 00:06:23,699
this will be keyword that we are going to
use and for CFG value, we will set it here.

90
00:06:23,699 --> 00:06:27,750
So I am going to X/Y plot.

91
00:06:27,750 --> 00:06:31,030
So in the first value I am going to select
CFG.

92
00:06:31,030 --> 00:06:40,300
To find the optimal CFG and weight values
for your newly generated compound or injected

93
00:06:40,300 --> 00:06:41,300
model.

94
00:06:41,300 --> 00:06:49,449
You should make a X/Y plot and see the which
one is producing the best outcome for you.

95
00:06:49,449 --> 00:06:54,910
And for the Y values we are going to use prompt
SR, like this.

96
00:06:54,910 --> 00:06:58,990
And in here we are going to put this as a
keyword.

97
00:06:58,990 --> 00:07:10,960
And then we are going to set the prompt strength,
like 1.0, 1.1, 1.2, like this, and then 1.3.

98
00:07:10,960 --> 00:07:15,259
Okay, 1.4.

99
00:07:15,259 --> 00:07:23,160
All right, then do not check this box, because
we are going to compare the effect of prompt

100
00:07:23,160 --> 00:07:24,860
strength and CFG values.

101
00:07:24,860 --> 00:07:28,540
Therefore, do not check keep -1 for seeds.

102
00:07:28,540 --> 00:07:34,330
For example, let's pick the batch size as
4 it will speed up if your graphic card VRAM

103
00:07:34,330 --> 00:07:35,569
is sufficient.

104
00:07:35,569 --> 00:07:41,479
I think this should be sufficient enough to
see the compare results and see which one

105
00:07:41,479 --> 00:07:49,199
of the weight and the CFG value performs best
on our newly generated model.

106
00:07:49,199 --> 00:07:54,599
After the results generated, just compare
them and see which one of the CFG value and

107
00:07:54,599 --> 00:08:02,220
the weight produced the best outcome And then
you can use that weight value in your prompts

108
00:08:02,220 --> 00:08:04,669
and the CFG value in your prompts.

109
00:08:04,669 --> 00:08:13,199
So this methodology would work on any custom
model that is using the same base model version

110
00:08:13,199 --> 00:08:14,860
as you are using.

111
00:08:14,860 --> 00:08:22,419
So the if the models are trained on version
1.5, and if your custom model the subject

112
00:08:22,419 --> 00:08:26,580
having model trained on version 1.5, then
it should work.

113
00:08:26,580 --> 00:08:31,949
You can try different weight values in here
to see how it is performing, And you should

114
00:08:31,949 --> 00:08:37,000
try different weight values here and the CFG
values here, as I have just shown with CFG

115
00:08:37,000 --> 00:08:38,000
scheme.

116
00:08:38,000 --> 00:08:44,039
So you see it is taking two hours to generate
why it will generate combination of these

117
00:08:44,039 --> 00:08:46,050
and batch size 4.

118
00:08:46,050 --> 00:08:53,900
If we calculate we got 12 multiplied by 11
grid, it will produce 12 multiplied by 11

119
00:08:53,900 --> 00:08:59,110
grid and then it in each generation it will
generate 4 images.

120
00:08:59,110 --> 00:09:07,010
So in total it will be a multiplication by,
like this, 528 images and among them you will

121
00:09:07,010 --> 00:09:08,779
be able to understand that.

122
00:09:08,779 --> 00:09:11,300
So this is all for this video.

123
00:09:11,300 --> 00:09:15,040
If you want to support us, you can become
our patron on Patreon.

124
00:09:15,040 --> 00:09:22,640
Please subscribe, like, share and write in
the comments that which what you want to see

125
00:09:22,640 --> 00:09:23,640
next.

126
00:09:23,640 --> 00:09:28,960
And you can also join our official discord
channel from about page of our channel and

127
00:09:28,960 --> 00:09:31,650
just click the official discord channel.

128
00:09:31,650 --> 00:09:33,250
So far, we have 4 patrons.

129
00:09:33,250 --> 00:09:35,510
I thank them very much.

130
00:09:35,510 --> 00:09:39,180
This is keeping us to produce more high quality
videos.

131
00:09:39,180 --> 00:09:46,350
And, as I said, just go to the playlist and
check out the playlist of our stable diffusion.

132
00:09:46,350 --> 00:09:47,380
Everything is in here.

133
00:09:47,380 --> 00:09:51,529
I will also put this video and the next videos
in here as well.

134
00:09:51,529 --> 00:09:52,529
Thank you very much.

135
00:09:52,529 --> 00:09:53,370
Hopefully see you later.

