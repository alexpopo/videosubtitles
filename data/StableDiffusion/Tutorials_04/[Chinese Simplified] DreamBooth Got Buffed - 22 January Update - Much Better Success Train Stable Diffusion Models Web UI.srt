1
00:00:00,000 --> 00:00:05,540
大家好。 在本视频中，我将向
您展示 Automatic1111 Web UI 的 DreamBooth 扩展的最新更新

2
00:00:05,540 --> 00:00:12,180
。 新的更新带来了
巨大的改进，可以教我们的受试者进入

3
00:00:12,180 --> 00:00:17,380
稳定扩散模型。 它比以前好 10 倍
。 这将是最佳设置的简短视频

4
00:00:17,380 --> 00:00:21,980
。 因此，如果您
对详细教程感兴趣，请先观看

5
00:00:21,980 --> 00:00:25,660
我非常详尽的 DreamBooth 教程。
让我给你看。

6
00:00:25,660 --> 00:00:30,740
这是您需要观看的视频。 因此，
让我向您展示

7
00:00:30,740 --> 00:00:35,420
我正在使用哪个版本的 DreamBooth 和 SD Web UI。 这
是 DreamBooth 修订版，这是

8
00:00:35,420 --> 00:00:41,020
SD 网络 UI 修订版。 要使用这些特定版本，
只需打开 Git Bash。 您需要

9
00:00:41,020 --> 00:00:47,120
从 Google 安装它，然后移动到
您的文件夹安装文件夹，就像这张

10
00:00:47,120 --> 00:00:56,320
CD 一样拖放。 然后像这样使用 git checkout
命令并粘贴提交 ID。

11
00:00:56,320 --> 00:01:03,080
现在它将结帐到该版本。 使用
最新的更新，您可以

12
00:01:03,080 --> 00:01:08,120

使用像这样的非常简单的命令获得非常程式化和非常好的结果。 你

13
00:01:08,120 --> 00:01:16,900
看，我刚刚将 Tomer Hanuka 添加到我的标记 ohwx 中
，并且像往常一样，我使用否定

14
00:01:16,900 --> 00:01:22,400
提示并且它能够很好地对其进行风格化。
这是我用过的数据集。 它不是

15
00:01:22,400 --> 00:01:28,580
很好，但也不是很糟糕。 所有的
背景和衣服都是不同的，

16
00:01:28,580 --> 00:01:35,260
不同的角度。 好的，现在让我向您展示
最佳设置。 这不是必需的，但请

17
00:01:35,260 --> 00:01:40,660
确保您选择了 1.5 版，
在此处修剪 ckpt，或者

18
00:01:40,660 --> 00:01:49,980
您要训练的任何模型。 转到
创建菜单中的 DreamBooth 选项卡。 给一个像教程一样的名字。

19
00:01:49,980 --> 00:01:55,860
现在我们正在检查是否是 512 像素模型
。 源检查点这是

20
00:01:55,860 --> 00:02:02,000
重要的一个：1.5 版修剪并创建
模型。 您应该收到这样的消息：

21
00:02:02,000 --> 00:02:08,120
检查点已成功提取到我们的工作
文件夹。 转到设置选项卡，然后在此处

22
00:02:08,120 --> 00:02:13,580
首先单击性能向导。 还有
新的 LoRA 版本。 但是，我还没

23
00:02:13,580 --> 00:02:18,460
有用 LoRA 得到好的结果。 希望我能
为 LoRA 制作另一个新视频，所以我不会

24
00:02:18,460 --> 00:02:25,660
选择它。 不要选中此复选框。 它
通常不起作用。 顺便说一句，有了

25
00:02:25,660 --> 00:02:31,820
新模型，有了新的更新，它的运行速度
比以前快得多。 就

26
00:02:31,820 --> 00:02:38,780
训练您的主题所需的时代数而言。
例如，我

27
00:02:38,780 --> 00:02:45,940
只用了 30 个 epochs 就可以训练我的脸，不像以前我用了
150 个 epochs。 所以仍然可以将其设置

28
00:02:45,940 --> 00:02:52,580
为 200，将其设置为 0，将其设置为 5，因为
它很快就会过度训练。 通过

29
00:02:52,580 --> 00:02:59,260
最新的更新，我认为他们已经修复了很多
问题，现在这不会自动

30
00:02:59,260 --> 00:03:05,940
检查。 帮我查了 我有 RTX 3060。
当你检查它时，它实际上会减少

31
00:03:05,940 --> 00:03:12,100
内存使用，但它会减慢你的
进程，这也是为了节省 VRAM。

32
00:03:12,100 --> 00:03:16,460
所以这在热身时是不变的。 没事。
我没有改变学习率。 它工作

33
00:03:16,460 --> 00:03:23,060
正常。 不要选中此框，也不要选中
此复选框。 在这里，

34
00:03:23,060 --> 00:03:30,460
了解您是否开始过度训练非常重要
。  Tomer Hanuka 拍摄的 ohwx man 照片

35
00:03:30,460 --> 00:03:37,900
。  ohwx 是我们的令牌。 这
是一个非常难得的令牌，人是阶级令牌。

36
00:03:37,900 --> 00:03:44,140
然后在高级选项卡中，如果你有超过
12GB的VRAM，你可以勾选这个“使用EMA”。

37
00:03:44,140 --> 00:03:49,060
它会提高你的成功率。 使用 8 位亚当。
我们有 16bf 和 xformers。 顺便说一句，让我也向

38
00:03:49,060 --> 00:03:55,460
您展示我使用的命令行参数。
我使用的唯一命令行参数是

39
00:03:55,460 --> 00:04:00,020
--xformers，而且我还使用了 disable
safe unpicked。 但这不是必需的。

40
00:04:00,020 --> 00:04:09,620
我没有添加 --no-half，因为这
是 SD 2.1 版所必需的。 这会

41
00:04:09,620 --> 00:04:16,820
减慢您的图像生成和训练速度，
但这只是 SD 2.1 所必需的。

42
00:04:16,820 --> 00:04:23,420
因此，如果您使用的不是 SD 2.1 版本，请
不要添加此内容。 它会减慢你的过程。

43
00:04:23,420 --> 00:04:27,340
我正在检查缓存潜伏。 这将
加快训练速度，但会增加

44
00:04:27,340 --> 00:04:33,060
VRAM 的使用。 因为我有 12GB，所以它工作正常。
我也在训练UNET。 如果你没有

45
00:04:33,060 --> 00:04:40,900
足够的 VRAM，那么你应该取消选中它。 好的，
当我取消选中它时出现错误。

46
00:04:40,900 --> 00:04:46,900
我想他们会修好的。 所以我保留这些
默认值。 如您所见，有一个新设置，即

47
00:04:46,900 --> 00:04:53,380
Weight Decay AdamW 优化器。
它说，

48
00:04:53,380 --> 00:04:58,020
当您使这个数字更大时，这将更加概括您的图像。 如果你
想让你的主题尽可能接近

49
00:04:58,020 --> 00:05:05,180
你。 默认为 0.01。 我确实将
其保留为默认值，并且效果很好。 和

50
00:05:05,180 --> 00:05:10,180
pad 标记：这些用于当您使用
[filewords] 和 shuffle 标签时，图像标题

51
00:05:10,180 --> 00:05:15,820
相关。 还有一个新的，另一种选择：
先前的损失。 我向扩展开发人员的开发人员询问了这个问题

52
00:05:15,820 --> 00:05:22,220
。 开发者的回答
是这样的：如你所见，Scale prior loss

53
00:05:22,220 --> 00:05:26,100
loss，随着训练的进行减少prior loss weight
。 当你启用它时，你会

54
00:05:26,100 --> 00:05:30,460
得到一个“最小先前损失”设置和
“先前损失目标”。 目标是：

55
00:05:30,460 --> 00:05:37,660
先验损失权重应该在哪个epoch达到最小值。
他还评论说不确定它是否重要

56
00:05:37,660 --> 00:05:42,700
或有帮助，但这有道理，因为
当我们训练我们的模型时，我们希望类

57
00:05:42,700 --> 00:05:46,940
图像的权重低于
实例图像的权重，因为模型应该已经

58
00:05:46,940 --> 00:05:52,540
更好地知道 主题。 我通过启用
和禁用它进行了测试。 我认为当

59
00:05:52,540 --> 00:05:57,540
未启用此功能时，它对我来说效果更好，但由
您来测试它。 然后我们进入

60
00:05:57,540 --> 00:06:03,780
概念。 好的，在目录中，像往常一样，
我们正在设置我们的第一个训练集

61
00:06:03,780 --> 00:06:08,740
目录。 这是我的训练集目录。
所以我复制它，我粘贴它，然后

62
00:06:08,740 --> 00:06:14,620
设置一个新的。 如果你有之前的分类图像，
就像我一样，你可以给它它的目录，

63
00:06:14,620 --> 00:06:21,340
或者你可以像这样给它一个新目录。
好的，现在 [filewords]。 人们对此感到非常

64
00:06:21,340 --> 00:06:26,380
困惑。 让我向您解释一下
这段视频中的实际情况。

65
00:06:26,380 --> 00:06:34,060
假设您在这里输入了 ohwx，并且您在
这里输入了 [filewords]。 所以这个在

66
00:06:34,060 --> 00:06:39,100
处理的时候就会变成这样。 例如，
假设我正在使用图像标题，

67
00:06:39,100 --> 00:06:46,720
就像在这个例子中一样，图像的标题
是这样的。 好吧，让我告诉你。

68
00:06:46,720 --> 00:06:54,100
因此，当我使用这样的配置时，
它会将我

69
00:06:54,100 --> 00:07:00,500
在 [filewords] 中写入的实例标记附加到开头。
然后它将阅读此处的字幕。

70
00:07:00,500 --> 00:07:05,100
所以最后的提示会是这样的。 如果
我在这里也添加一个词，假设是example

71
00:07:05,100 --> 00:07:14,100
word，那么这个example word将被附加到
这里。 所以这也等于这样使用

72
00:07:14,100 --> 00:07:19,580
。 当你这样使用它的时候，它就会变得和
这个一模一样。 这

73
00:07:19,580 --> 00:07:24,940
就是 [filewords] 和实例令牌的工作方式。
我没有使用任何 [filewords]

74
00:07:24,940 --> 00:07:32,540
和图像标题。 所以我将
实例令牌设置为 ohwx man。 所以

75
00:07:32,540 --> 00:07:39,660
ohwx 是我们的令牌，而 man 是我们的
班级。 在这个视频中，我非常清楚

76
00:07:39,660 --> 00:07:45,020
、非常详细、非常技术性地解释了
稳定扩散是如何工作的，

77
00:07:45,020 --> 00:07:53,140
它是如何由向量和不同的标记组成的。
对于类提示，我们使用的是

78
00:07:53,140 --> 00:08:01,380
人的照片和示例图像提示：我们
使用的是 ohwx 人的照片，如你

79
00:08:01,380 --> 00:08:10,220
所见，然后，每个实例的类图像，
我使用了 48 张图像，并在

80
00:08:10,220 --> 00:08:14,520
保存选项卡中，确保你 正在生成
一个 ckpt 文件并在训练期间保存，

81
00:08:14,520 --> 00:08:21,860
因为当你看到训练过度时，
你会看到使用某些检查点

82
00:08:21,860 --> 00:08:31,300
，然后单击保存设置。 好的，我认为
一切都准备就绪了。 只需

83
00:08:31,300 --> 00:08:36,780
点击训练选项卡，它就会开始生成
分类图像，然后

84
00:08:36,780 --> 00:08:42,140
开始训练模型。 你看，
分类图像非常奇怪

85
00:08:42,140 --> 00:08:48,540
。 如果您精心挑选好的分类
图像，那么它可能会提高您的成功率。 由

86
00:08:48,540 --> 00:08:53,500
您来测试。 但我实际上并没有触及
分类图像。 我只是

87
00:08:53,500 --> 00:08:59,060
使用它生成的任何东西。 好的，这是我训练
过程中生成的训练样本

88
00:08:59,060 --> 00:09:05,700
。 所以，正如你所看到的，即使在
第 10 个纪元，我也

89
00:09:05,700 --> 00:09:12,520
每 10 个纪元保存一次预览图像和检查点。 它
已经学会了一个很好的我的主题，

90
00:09:12,520 --> 00:09:19,140
我的脸。 在 30 个 epoch 之后，我们
通过使用 sanity 失去了样式。

91
00:09:19,140 --> 00:09:24,520
如您所见，在我们使用 Tomer
Hanuka 风格的理智中。 所以我决定

92
00:09:24,520 --> 00:09:31,860
只对 30 个 epoch 进行测试，结果
非常好，正如我向您展示的那样。 此外，

93
00:09:31,860 --> 00:09:38,740
当我们分析时，您会看到，现在我们
甚至不需要增加

94
00:09:38,740 --> 00:09:46,300
令牌的提示强调，只需像这样使用 1.1 强调，
它就可以工作，工作得很好。

95
00:09:46,300 --> 00:09:56,460
通过 30 步和 720 步的训练，
它能够完全风格化我的脸，并能够

96
00:09:56,460 --> 00:10:01,820
生成非常漂亮的图像。 这
与之前

97
00:10:01,820 --> 00:10:07,620
Automatic1111 的 DreamBooth 扩展的训练不同。
因此，现在，情况真的

98
00:10:07,620 --> 00:10:13,060
不同了，真的有所改善，我认为他们
所做的是现在他们能够适当地

99
00:10:13,060 --> 00:10:19,100
保持之前的损失，而以前他们
无法保持。 所以现在，只需

100
00:10:19,100 --> 00:10:27,140
很少的 epoch，该模型就能够
很好地学习我们的主题。 您仍然

101
00:10:27,140 --> 00:10:34,180
可以对不同的时期进行测试，
为此，您只需要使用 X/Y

102
00:10:34,180 --> 00:10:41,260
图，在这里您可以给出检查点
名称。 您会看到它显示了所有

103
00:10:41,260 --> 00:10:46,300
这样的名称，只需删除您
不想测试的名称即可。 并且，Y 图。 我建议

104
00:10:46,300 --> 00:10:52,620
你测试CFG值。 您可以测试
8、7、9、10、11、12 以及任何

105
00:10:52,620 --> 00:10:59,540
您想要的。 当你进行测试时，你可以看到
哪个时代最适合你。 我

106
00:10:59,540 --> 00:11:07,140
对最新的更新非常满意，因为
它确实提高了培训

107
00:11:07,140 --> 00:11:13,500
质量。 因此，请查看最新的 DreamBooth
扩展。 非常感谢您的收看。

108
00:11:13,500 --> 00:11:19,260
请喜欢，订阅并发表评论。
您可以加入我们的 Discord 频道，讨论

109
00:11:19,260 --> 00:11:24,300
一切并提出任何问题。 转到
我们 YouTube 频道的“关于”选项卡，在

110
00:11:24,300 --> 00:11:28,820
底部您会看到官方的 Discord 频道链接。
如果您在 Patreon 上支持我们，我将

111
00:11:28,820 --> 00:11:34,460
不胜感激。 这让我能够
做更多的研究并制作质量更好的

112
00:11:34,460 --> 00:11:37,780
视频。 希望
稍后在另一个视频中见到你。

