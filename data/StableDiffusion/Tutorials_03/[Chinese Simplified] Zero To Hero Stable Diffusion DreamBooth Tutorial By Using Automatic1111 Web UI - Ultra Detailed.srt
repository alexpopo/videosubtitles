1
00:00:02,690 --> 00:00:03,690
大家好。

2
00:00:03,690 --> 00:00:07,690
欢迎来到对初学者最友好
但最先进和最新的 Stable

3
00:00:07,690 --> 00:00:09,610
Diffusion DreamBooth 模型培训教程。

4
00:00:09,610 --> 00:00:14,990
在本指南视频中，我将使用
最新的 Automatic1111 Web UI 和 DreamBooth

5
00:00:14,990 --> 00:00:16,170
扩展。

6
00:00:16,170 --> 00:00:20,421
DreamBooth 插件的界面和功能
已发生显着变化，因此

7
00:00:20,421 --> 00:00:23,600
所有其他教程现在都已过时。

8
00:00:23,600 --> 00:00:27,609
我已经试验了 7 天以上，
以找到最佳设置和训练

9
00:00:27,609 --> 00:00:28,609
参数。

10
00:00:28,609 --> 00:00:33,829
此外，我试图了解每个选项的
作用，并且我已经在本视频中解释了所有内容

11
00:00:33,829 --> 00:00:34,870
。

12
00:00:34,870 --> 00:00:37,950
在开始之前，让我提供一些快速
信息。

13
00:00:37,950 --> 00:00:42,510
Stable Diffusion 是一个文本到图像的生成
公共 AI 模型，Automatic1111 web

14
00:00:42,510 --> 00:00:47,690
UI 是开源社区开发的一个工具，
可以轻松使用 Stable Diffusion。

15
00:00:47,690 --> 00:00:52,219
DreamBooth 是一种 AI 算法，可让
您

16
00:00:52,219 --> 00:00:57,320
非常成功地向现有的稳定扩散模型教授新主题甚至风格，
例如教授人脸。

17
00:00:57,320 --> 00:01:02,480
在本教程中，我将使用新
安装的 Automatic1111 web UI

18
00:01:02,480 --> 00:01:05,820
使用 Stable Diffusion 1.5 正式
版来教我的脸。

19
00:01:05,820 --> 00:01:11,560
我还将展示如何
在 Stable Diffusion 2.1 版上进行相同的训练。

20
00:01:11,560 --> 00:01:16,990
此外，我将向您展示如何将经过
训练的对象（在本例中是我的脸）

21
00:01:16,990 --> 00:01:19,990
注入任何自定义模型并获得惊人的结果。

22
00:01:19,990 --> 00:01:24,579
我将使用
非常流行且质量非常高的自定义

23
00:01:24,579 --> 00:01:26,540
模型 Protogen x3.4 来演示示例。

24
00:01:26,540 --> 00:01:32,299
使用这种注入方法，您可以使用
任何已发布的自定义模型并获得

25
00:01:32,299 --> 00:01:33,620
更好的结果。

26
00:01:33,620 --> 00:01:37,250
你甚至不需要重新训练你的主题
就可以工作。

27
00:01:37,250 --> 00:01:42,200
这种方法提供的图像质量如此之高，
以至于您甚至无法通过 Lensa 或 Midjourney 等付费服务获得它们

28
00:01:42,200 --> 00:01:44,659
。

29
00:01:44,659 --> 00:01:49,380
Automatic1111 网络用户界面不断
更新，所以让我向您展示我

30
00:01:49,380 --> 00:01:53,500
使用的来自官方存储库的版本。

31
00:01:53,500 --> 00:01:57,070
这是 Stable Diffusion Web UI 的官方存储库
。

32
00:01:57,070 --> 00:02:00,030
它最近被撤下了，但
现在又回来了。

33
00:02:00,030 --> 00:02:05,149
因此，如果您找不到此 URL，请
查看视频，我会更新

34
00:02:05,149 --> 00:02:11,180
视频的描述和视频的评论，
以便您找到 Automatic1111 的最新链接。

35
00:02:11,180 --> 00:02:20,190
所以我们使用的提交是在
2023 年 1 月 7 日 9 小时前发布的。

36
00:02:20,190 --> 00:02:25,129
如果您不知道如何安装 Automatic1111
web UI，我有一个很好的教程。

37
00:02:25,129 --> 00:02:27,960
这是我们 YouTube 频道的主页。

38
00:02:27,960 --> 00:02:34,000
转到播放列表，在这里您将看到 Stable
Diffusion DreamBooth 播放列表，在此

39
00:02:34,000 --> 00:02:38,740
播放列表中，最简单的方法是在 PC 上安装和运行
Stable Diffusion Web UI。

40
00:02:38,740 --> 00:02:43,629
我将把这个视频的链接放到描述中，
你也可以在 Web UI 中观看如何使用 Stable Diffusion

41
00:02:43,629 --> 00:02:46,420
2.1 版和不同模型
。

42
00:02:46,420 --> 00:02:47,980
这也很重要。

43
00:02:47,980 --> 00:02:51,769
我还将把这个视频的链接也放到
描述中。

44
00:02:51,769 --> 00:02:52,980
还有一件事。

45
00:02:52,980 --> 00:02:54,470
这是常问的。

46
00:02:54,470 --> 00:03:00,599
如果您遇到任何问题，请转到
我们频道的“关于”页面，您将在此处看到

47
00:03:00,599 --> 00:03:01,739
我们的 Discord 频道链接。

48
00:03:01,739 --> 00:03:03,760
如您所见，我目前正在徘徊。

49
00:03:03,760 --> 00:03:08,400
你可以加入我们的 Discord 频道，
遇到任何问题都可以问我。

50
00:03:08,400 --> 00:03:11,920
所以这是我们稳定扩散的开始屏幕
。

51
00:03:11,920 --> 00:03:14,780
首先让我们开始安装我们的
扩展程序 DreamBooth。

52
00:03:14,780 --> 00:03:21,860
为此，请转到扩展选项卡，单击可用的
加载来源，然后您将在此处看到 DreamBooth

53
00:03:21,860 --> 00:03:23,000
扩展。

54
00:03:23,000 --> 00:03:26,349
当您键入 DreamBooth 时，它会列在
此处。

55
00:03:26,349 --> 00:03:29,920
我只是点击安装，它正在
安装。

56
00:03:29,920 --> 00:03:35,750
您应该会在此处看到一条消息：好的，它
已安装。

57
00:03:35,750 --> 00:03:38,330
我们有一个错误，但这不是问题。

58
00:03:38,330 --> 00:03:39,890
它仍然有效。

59
00:03:39,890 --> 00:03:45,440
所以你看，我们在 CMD 窗口上有一条消息，
并且还作为 DreamBooth 扩展安装到 C web UI 教程

60
00:03:45,440 --> 00:03:47,760
扩展中。

61
00:03:47,760 --> 00:03:53,140
现在我们必须重新启动 CMD 窗口，因为
我们是第一次安装，这是

62
00:03:53,140 --> 00:03:54,150
必要的。

63
00:03:54,150 --> 00:03:56,299
否则它不会工作。

64
00:03:56,299 --> 00:03:58,230
让我们关闭。

65
00:03:58,230 --> 00:03:59,670
让我们重新开始。

66
00:03:59,670 --> 00:04:02,470
OK，重启完成。

67
00:04:02,470 --> 00:04:09,170
让我们刷新，然后返回到扩展
并在每次启动时检查更新。

68
00:04:09,170 --> 00:04:12,020
好的，刚刚更新了。

69
00:04:12,020 --> 00:04:14,950
所以我只是单击应用并重新启动 UI。

70
00:04:14,950 --> 00:04:16,760
好的，完成了。 第

71
00:04:16,760 --> 00:04:19,630
一次安装后。

72
00:04:19,630 --> 00:04:23,040
您不需要再次重新启动 CMD 窗口
。

73
00:04:23,040 --> 00:04:26,389
所以你看，这就是这些东西
更新的频率。

74
00:04:26,389 --> 00:04:30,820
从字面上看，它刚刚更新，如
您所见。

75
00:04:30,820 --> 00:04:33,340
所以你应该经常检查最新版本。

76
00:04:33,340 --> 00:04:35,570
现在我们可以开始我们的教程了。

77
00:04:35,570 --> 00:04:36,570
我们现在。

78
00:04:36,570 --> 00:04:38,330
我们在界面中看到 DreamBooth 选项卡。

79
00:04:38,330 --> 00:04:39,740
我们点击那个。

80
00:04:39,740 --> 00:04:44,910
这是您
要生成我们的模型并训练我们的脸或

81
00:04:44,910 --> 00:04:46,509
新主题的界面。

82
00:04:46,509 --> 00:04:51,410
首先，我们需要生成我们的模型。

83
00:04:51,410 --> 00:04:53,310
您可以在此处简单地输入任何名称。

84
00:04:53,310 --> 00:04:54,310
没关系。

85
00:04:54,310 --> 00:05:02,580
因此，我将以 Web UI 和
我的模型的标识符提示输入，这将是 ohwx。

86
00:05:02,580 --> 00:05:05,949
我将解释为什么它会是 ohwx。

87
00:05:05,949 --> 00:05:08,520
然后我们需要检查源点。

88
00:05:08,520 --> 00:05:12,570
您也可以从 Hugging Face 导入，但
我不建议没有必要。

89
00:05:12,570 --> 00:05:17,090
我正在检查 1.5 版 Pruned ckpt。

90
00:05:17,090 --> 00:05:24,110
因此 1.5 版修剪了
StableDiffusion 1.5 官方存储库中可用的 ckpt。

91
00:05:24,110 --> 00:05:26,020
你可以从这里下载它。

92
00:05:26,020 --> 00:05:33,150
为什么我们使用 Pruned ckpt，而不是 pruned-emaonly
ckpt，因为这更适合训练

93
00:05:33,150 --> 00:05:34,229
新科目。

94
00:05:34,229 --> 00:05:39,080
当你点击这里时，你可以
点击这里下载它。 将

95
00:05:39,080 --> 00:05:44,169
其放入模型文件夹后，
它也将在此处可用，如您

96
00:05:44,169 --> 00:05:46,130
所见。

97
00:05:46,130 --> 00:05:48,080
好的。

98
00:05:48,080 --> 00:05:51,010
然后只需单击创建模型按钮。

99
00:05:51,010 --> 00:05:54,490
好的，你明白了。

100
00:05:54,490 --> 00:05:59,070
我们有一个消息检查点已成功
提取到此文件夹。 在

101
00:05:59,070 --> 00:06:00,110
哪儿。

102
00:06:00,110 --> 00:06:01,360
我来给你展示。

103
00:06:01,360 --> 00:06:04,500
它在 Web UI 教程中。

104
00:06:04,500 --> 00:06:11,300
让我们转到我们的模型和 DreamBooth 内部，
Web UI ohwx 内部并在这里工作。

105
00:06:11,300 --> 00:06:17,810
这些实际上是我们刚刚构建的模型的权重
。

106
00:06:17,810 --> 00:06:19,349
让我们继续。

107
00:06:19,349 --> 00:06:21,840
现在这里选择这个模型。

108
00:06:21,840 --> 00:06:24,550
这是我们进行选择的地方。

109
00:06:24,550 --> 00:06:28,639
做出此选择后，我们将训练
所选模型。

110
00:06:28,639 --> 00:06:29,639
是的。

111
00:06:29,639 --> 00:06:30,639
好的。

112
00:06:30,639 --> 00:06:33,200
现在让我们转到此处的设置选项卡。

113
00:06:33,200 --> 00:06:35,160
首先点击性能向导。

114
00:06:35,160 --> 00:06:39,900
它将根据
您的 GPU 的 VRAM 设置参数。

115
00:06:39,900 --> 00:06:44,789
如果你的 GPU 小于 12GB，那么
DreamBooth 真的很难用。 很

116
00:06:44,789 --> 00:06:45,789
遗憾。

117
00:06:45,789 --> 00:06:48,750
您可以使用 LoRA，但这是另一个视频的主题
。

118
00:06:48,750 --> 00:06:52,270
实际上，它与该视频几乎相同，
但是有。

119
00:06:52,270 --> 00:06:56,900
有一些技巧，我已经
有了 LoRA 的视频。

120
00:06:56,900 --> 00:07:00,840
所以看完这个视频后，如果你看
那个视频，LoRA 视频。

121
00:07:00,840 --> 00:07:05,130
您可以轻松地将 LoRA 应用到您的训练中。

122
00:07:05,130 --> 00:07:06,130
它就在这里。

123
00:07:06,130 --> 00:07:08,530
您将了解如何使用 Stable Diffusion LoRA 进行训练
。

124
00:07:08,530 --> 00:07:13,160
我还将把这个视频的链接也放到
描述中。

125
00:07:13,160 --> 00:07:16,449
因此每个图像时代的训练步骤。

126
00:07:16,449 --> 00:07:19,000
首先，让我解释一下什么是epoch。

127
00:07:19,000 --> 00:07:26,009
我们将有一个训练数据集，即
我们要教授的科目的图片。

128
00:07:26,009 --> 00:07:29,860
在这种情况下，我要自学。

129
00:07:29,860 --> 00:07:33,280
我将使用我自己的 12 张图片。

130
00:07:33,280 --> 00:07:38,090
因此，一个epoch就是12步。

131
00:07:38,090 --> 00:07:44,280
所以每一步都是一个训练步骤，每个时期都对
所有训练图像进行一次训练

132
00:07:44,280 --> 00:07:45,280
。

133
00:07:45,280 --> 00:07:50,699
所以在我的例子中，一个纪元意味着 12 个步骤，因为
我必须有训练图像。

134
00:07:50,699 --> 00:07:52,490
我们想要多少个纪元？

135
00:07:52,490 --> 00:07:57,169
对于面孔训练，通常建议使用
150。

136
00:07:57,169 --> 00:08:00,690
因此，当您进入概念时，只需单击
与人一起训练。

137
00:08:00,690 --> 00:08:05,490
它将为人设置最合适的值
。

138
00:08:05,490 --> 00:08:07,699
所以你看，现在它设置为 150。

139
00:08:07,699 --> 00:08:13,220
但是，你可以根据需要设置它，
并且可以使用某些检查点。

140
00:08:13,220 --> 00:08:14,220
我会解释的。

141
00:08:14,220 --> 00:08:17,270
所以我打算让它变成 300。

142
00:08:17,270 --> 00:08:22,379
以及你想在每个纪元之间等待多少时间
：零，这也是零。

143
00:08:22,379 --> 00:08:24,020
好的，这很重要。

144
00:08:24,020 --> 00:08:29,110
我们希望多长时间保存一次训练。

145
00:08:29,110 --> 00:08:34,719
您知道，如果您的计算机崩溃，如果您
取消训练，或者发生任何情况，

146
00:08:34,719 --> 00:08:40,380
您都可以从最新
保存的模型继续。

147
00:08:40,380 --> 00:08:42,520
因此，这很重要。

148
00:08:42,520 --> 00:08:48,100
此外，如果您进行了过度训练并且想要
使用之前的训练检查点，您还

149
00:08:48,100 --> 00:08:49,100
需要进行保存。

150
00:08:49,100 --> 00:08:50,720
所以我打算将其设置为 10。请

151
00:08:50,720 --> 00:08:55,910
注意，在进行 DreamBooth
培训时，每次保存通常需要大约 4 到

152
00:08:55,910 --> 00:08:58,279
5 GB。

153
00:08:58,279 --> 00:09:04,430
所以如果你没有太多的硬盘空间，
你可能需要设置一个更高的数字。 例如，

154
00:09:04,430 --> 00:09:08,800
这是在每个时期保存预览图像，
或者为

155
00:09:08,800 --> 00:09:09,800
您想要的任何时期数保存预览图像。

156
00:09:09,800 --> 00:09:13,980
这不会占用空间，但这会减慢
您的速度。

157
00:09:13,980 --> 00:09:17,480
所以我打算将其保留为五个。

158
00:09:17,480 --> 00:09:19,580
批量大小：现在，这非常重要。

159
00:09:19,580 --> 00:09:23,500
如果你增加批量大小，它会显着
加快你的训练。

160
00:09:23,500 --> 00:09:29,600
但是，这也会显着增加您的 GPU
内存使用量。

161
00:09:29,600 --> 00:09:35,610
如果增加这些数字，则需要将
它们均等地增加以获得

162
00:09:35,610 --> 00:09:36,610
最佳结果。

163
00:09:36,610 --> 00:09:40,420
所以现在，举例来说，它的速度将
快近四倍。

164
00:09:40,420 --> 00:09:45,649
此外，请确保您的训练图像
计数可被此数字整除。

165
00:09:45,649 --> 00:09:54,800
所以二乘以二得四，你的
训练图像数量必须能被

166
00:09:54,800 --> 00:09:55,800
四整除。

167
00:09:55,800 --> 00:10:02,130
所以它可以是四张图片、八张图片、12张
图片、16张图片、20张图片，但不应该

168
00:10:02,130 --> 00:10:03,570
是17张图片。

169
00:10:03,570 --> 00:10:06,360
好的，这是公式。

170
00:10:06,360 --> 00:10:12,550
假设您有 16 GB 的 GPU RAM，
那么您可以将其增加三个。

171
00:10:12,550 --> 00:10:17,610
然后你应该有 9 或 18 或 27
或 36 张图像。

172
00:10:17,610 --> 00:10:18,760
这就是公式。

173
00:10:18,760 --> 00:10:22,529
我现在要一个一个地离开这个
。

174
00:10:22,529 --> 00:10:28,380
另外，另一件事是，如果你把这个二
加二，像这样，它会是四次。

175
00:10:28,380 --> 00:10:35,010
然后你还需要将学习率提高
四倍，就像这个和这个。

176
00:10:35,010 --> 00:10:36,480
否则会很慢。

177
00:10:36,480 --> 00:10:40,360
它还需要加快学习
速度。

178
00:10:40,360 --> 00:10:42,880
增加多少就增加多少。

179
00:10:42,880 --> 00:10:46,800
由于我将一一使用，因此我将
保留默认学习率。

180
00:10:46,800 --> 00:10:50,730
好的，调零时将渐变设置为无。

181
00:10:50,730 --> 00:10:55,899
如果您选择此项，它会增加 GPU
RAM 的使用。

182
00:10:55,899 --> 00:10:57,990
你怎么知道的？

183
00:10:57,990 --> 00:11:03,970
DreamBooth 有一个 wiki 页面，这里
有 RAM 使用设置。

184
00:11:03,970 --> 00:11:06,000
我来给你展示。

185
00:11:06,000 --> 00:11:10,470
在这里确定：已知使用更多 VRAM 的设置。

186
00:11:10,470 --> 00:11:12,420
正如我刚才解释的那样，批量大小很高。

187
00:11:12,420 --> 00:11:18,540
归零时将梯度设置为无，
这里就是这些设置。

188
00:11:18,540 --> 00:11:23,420
所以当你检查这个时，它会使用更多的 VRAM
然后使用 EMA。

189
00:11:23,420 --> 00:11:24,420
好的。

190
00:11:24,420 --> 00:11:25,420
现在让我们继续。

191
00:11:25,420 --> 00:11:26,420
我会解释。

192
00:11:26,420 --> 00:11:31,070
梯度检查点：这是一种
通过清除激活来减少内存使用的技术。

193
00:11:31,070 --> 00:11:35,440
所以最好检查一下。

194
00:11:35,440 --> 00:11:37,959
然后我们不只是路过这里。

195
00:11:37,959 --> 00:11:42,230
这些只是可以玩的更高级的东西
。

196
00:11:42,230 --> 00:11:47,529
当你习惯了如何使用DreamBooth后，
你就可以改变它们，但在学习

197
00:11:47,529 --> 00:11:49,910
阶段就让它们保持原样。

198
00:11:49,910 --> 00:11:53,920
如果你把这些设置得太高，它会被
训练得太快。

199
00:11:53,920 --> 00:11:56,670
但是，它也很容易过度训练。

200
00:11:56,670 --> 00:12:01,220
如果你让它们太低，那么你可能永远
不会训练它。

201
00:12:01,220 --> 00:12:05,910
所以这是一种实验性的东西，
你需要做很多实验。

202
00:12:05,910 --> 00:12:07,220
图像处理和分辨率。

203
00:12:07,220 --> 00:12:08,220
这个很重要。

204
00:12:08,220 --> 00:12:18,620
当您使用基于
版本 1.X 的模型版本时，它们是 512 像素。

205
00:12:18,620 --> 00:12:24,459
如果您使用 2.1 版，则还有
768 像素版本。

206
00:12:24,459 --> 00:12:28,880
所以你需要根据
你的基础模型的版本来设置它。

207
00:12:28,880 --> 00:12:30,970
好的，基本模型，源代码检查点。

208
00:12:30,970 --> 00:12:32,209
我们在这里检查过。

209
00:12:32,209 --> 00:12:35,949
由于我们使用的是1.5版本，正式版。

210
00:12:35,949 --> 00:12:39,410
它是 512 像素。

211
00:12:39,410 --> 00:12:40,790
不要应用水平翻转。

212
00:12:40,790 --> 00:12:42,660
这对面子不好。

213
00:12:42,660 --> 00:12:44,149
中心作物。

214
00:12:44,149 --> 00:12:46,990
如果您的图像没有被裁剪，您应该
检查一下。

215
00:12:46,990 --> 00:12:49,940
我将解释如何设置图像。

216
00:12:49,940 --> 00:12:53,640
由于我的图像是中心裁剪的，所以我没有
检查它。

217
00:12:53,640 --> 00:12:54,640
理智样本提示。

218
00:12:54,640 --> 00:12:55,700
好的，这很重要。

219
00:12:55,700 --> 00:13:02,959
我们将使用此提示查看
模型的整体训练。

220
00:13:02,959 --> 00:13:07,200
但是，就是否过度训练而言。

221
00:13:07,200 --> 00:13:11,040
在培训培训期间，我会解释。

222
00:13:11,040 --> 00:13:16,350
所以我要在这里输入
Tomer Hanuka 拍摄的 ohwx man 照片。

223
00:13:16,350 --> 00:13:20,050
我将解释为什么输入此提示。

224
00:13:20,050 --> 00:13:22,130
还有托默·哈努卡 (Tomer Hanuka)。

225
00:13:22,130 --> 00:13:23,360
你会明白的。

226
00:13:23,360 --> 00:13:26,040
杂项、预训练的 VAE 或路径。

227
00:13:26,040 --> 00:13:28,480
这些是高级的东西，你
目前不需要。

228
00:13:28,480 --> 00:13:29,480
好的。

229
00:13:29,480 --> 00:13:31,529
好的，高级的东西。

230
00:13:31,529 --> 00:13:33,589
这个很重要。

231
00:13:33,589 --> 00:13:38,010
如果您选中使用 EMA，那么它将
提高您的培训质量。

232
00:13:38,010 --> 00:13:41,100
但是，它也会显着增加 RAM 的使用。

233
00:13:41,100 --> 00:13:45,880
使用八位 Adam：这将减少 RAM 的
使用。

234
00:13:45,880 --> 00:13:47,790
BF16：这也是。

235
00:13:47,790 --> 00:13:50,820
这也将减少 RAM 的使用。

236
00:13:50,820 --> 00:13:54,870
xFormers：这将显着提高
您的训练速度。

237
00:13:54,870 --> 00:13:59,740
Cache Latent：这也会减少 VRAM 的
使用。

238
00:13:59,740 --> 00:14:02,759
所有这些实际上都写在这个
页面上。

239
00:14:02,759 --> 00:14:05,800
维基顶部内存不足。

240
00:14:05,800 --> 00:14:08,860
我会把这个放到描述中。

241
00:14:08,860 --> 00:14:11,949
所以你看到这些都在减少 RAM 的
使用。

242
00:14:11,949 --> 00:14:19,329
实际上，它说缓存 Latent 增加了，
但据我所知这并没有增加。

243
00:14:19,329 --> 00:14:22,110
但是你可以测试一下。

244
00:14:22,110 --> 00:14:25,019
所以文本编码器训练的步长比。

245
00:14:25,019 --> 00:14:27,700
这将提高您的培训质量。

246
00:14:27,700 --> 00:14:31,730
但是，它也会增加
图形卡的 RAM 使用率。

247
00:14:31,730 --> 00:14:37,009
所以如果你遇到内存不足的错误，你
应该把这个设置为零。

248
00:14:37,009 --> 00:14:44,120
但面部的最佳值为 0.7，
风格为 0.2。

249
00:14:44,120 --> 00:14:46,410
还有其他你不需要和他们一起玩的东西
。

250
00:14:46,410 --> 00:14:49,240
它们是更高级的东西。

251
00:14:49,240 --> 00:14:51,800
好的，现在是概念。

252
00:14:51,800 --> 00:14:54,959
这是非常重要的部分。

253
00:14:54,959 --> 00:14:59,970
您可以设置 [filewords]、提示和目录。

254
00:14:59,970 --> 00:15:03,390
所以首先我们必须设置我们的训练
数据集。

255
00:15:03,390 --> 00:15:04,850
训练数据集目录。

256
00:15:04,850 --> 00:15:07,970
我的训练数据集在哪里？

257
00:15:07,970 --> 00:15:12,579
它在我的图片文件夹中，
在 Best DB 中。

258
00:15:12,579 --> 00:15:19,389
所以所有这些图像现在都是 512 x 512
像素。

259
00:15:19,389 --> 00:15:21,130
让我展示一下他们的原始版本。

260
00:15:21,130 --> 00:15:26,050
所以他们的原始版本在这里。

261
00:15:26,050 --> 00:15:27,529
我是如何设置它们的？

262
00:15:27,529 --> 00:15:31,759
我已经使用 Paint .NET 根据需要裁剪它们
。

263
00:15:31,759 --> 00:15:32,759
例如。

264
00:15:32,759 --> 00:15:36,060
让我告诉你：顺便说一下，paint dot net 是一个免费工具
。

265
00:15:36,060 --> 00:15:40,769
你可以从谷歌安装它。

266
00:15:40,769 --> 00:15:46,589
只需单击，就像这样，然后我就用
正方形裁剪它们。

267
00:15:46,589 --> 00:15:52,149
所以我点击矩形，选择，然后点击这里，
然后在这里，像这样固定比例，然后

268
00:15:52,149 --> 00:15:55,769
你可以选择你想要的图像的任何部分
。

269
00:15:55,769 --> 00:15:57,230
仅举个例子。

270
00:15:57,230 --> 00:16:01,910
然后你可以控制-C 控制-N 它会
粘贴到一个新的地方。

271
00:16:01,910 --> 00:16:03,220
你可以保存它。

272
00:16:03,220 --> 00:16:04,220
或者在这里。

273
00:16:04,220 --> 00:16:10,730
您可以像这样使用 control-R 将它们调整为非常低的分辨率
。 它将

274
00:16:10,730 --> 00:16:13,870
像这样打开调整大小类型，然后 control-V 并展开。

275
00:16:13,870 --> 00:16:15,740
你看，现在它被裁剪了。

276
00:16:15,740 --> 00:16:17,660
或者，您可以使用 Birme .NET。

277
00:16:17,660 --> 00:16:22,550
Birme dot net 是一个著名的图片裁剪网站。

278
00:16:22,550 --> 00:16:25,069
它在社区中很常用。

279
00:16:25,069 --> 00:16:30,170
例如，您可以在那里上传任何图像
并裁剪它们。

280
00:16:30,170 --> 00:16:33,660
例如，让我们上传这张图片。

281
00:16:33,660 --> 00:16:37,490
这些目前是方形的，但如果它们
不是方形的，它也会自动让

282
00:16:37,490 --> 00:16:38,490
你方形。

283
00:16:38,490 --> 00:16:42,769
让我展示一下：好的，你看，这两张图片都
没有被裁剪。

284
00:16:42,769 --> 00:16:48,261
因此，您可以像这样用鼠标裁剪它们
：设置位置，然后

285
00:16:48,261 --> 00:16:51,040
从此处设置分辨率：512、512。

286
00:16:51,040 --> 00:16:55,750
如果您使用 SD 2.1 版，则它们将
是七个 768 像素。

287
00:16:55,750 --> 00:16:58,790
好的，您还可以使用自动检测图像
焦点。

288
00:16:58,790 --> 00:16:59,790
不要调整大小。

289
00:16:59,790 --> 00:17:01,380
你可以点击这里。

290
00:17:01,380 --> 00:17:03,000
如果你检查，不要调整大小，它不会。

291
00:17:03,000 --> 00:17:06,030
他们不会调整到这个分辨率。

292
00:17:06,030 --> 00:17:08,709
然后保存一个zip，它们将全部保存
为zip。

293
00:17:08,709 --> 00:17:12,510
然后您可以使用您拥有的软件提取它们
。

294
00:17:12,510 --> 00:17:17,000
如果您没有像 Winrar Windows 这样的任何软件
仍然可以提取它们。

295
00:17:17,000 --> 00:17:18,040
好的。

296
00:17:18,040 --> 00:17:22,140
如果您做不到，请加入 Discord，
希望我能帮助您。

297
00:17:22,140 --> 00:17:23,939
所以数据集目录。

298
00:17:23,939 --> 00:17:27,119
当您准备好图像后，我们将进入
它的路径。

299
00:17:27,119 --> 00:17:28,900
所以这是我的。

300
00:17:28,900 --> 00:17:32,100
让我进入文件夹目录。

301
00:17:32,100 --> 00:17:34,929
我单击此处，您会看到我能够选择
路径。

302
00:17:34,929 --> 00:17:38,650
我用 control-C 复制它，将它粘贴到这里 (ctrl-v)。

303
00:17:38,650 --> 00:17:43,440
所以这是我的训练
图像所在的目录。

304
00:17:43,440 --> 00:17:46,800
分类目录： 那么，什么是分类？

305
00:17:46,800 --> 00:17:54,190
分类是通用图像，我们
将使用它们来避免过度训练我们的模型并

306
00:17:54,190 --> 00:17:58,450
保持模型的内部完整性。

307
00:17:58,450 --> 00:18:02,530
这样整个模型就不会变得
像我们一样。

308
00:18:02,530 --> 00:18:03,530
好的。

309
00:18:03,530 --> 00:18:06,700
因此，为此我将只生成一个新文件夹。

310
00:18:06,700 --> 00:18:10,190
是的，我已经复制粘贴了路径。

311
00:18:10,190 --> 00:18:13,520
我将把它设置为 web UI 教程。

312
00:18:13,520 --> 00:18:16,950
您还可以输入现有的另一个目录。

313
00:18:16,950 --> 00:18:18,010
没事。

314
00:18:18,010 --> 00:18:25,620
Instance token：现在 [filewords] 用于
为每个训练图像设置不同的描述

315
00:18:25,620 --> 00:18:26,620
。

316
00:18:26,620 --> 00:18:29,620
这是非常非常先进的，很难做到。

317
00:18:29,620 --> 00:18:34,290
所以我将在教程视频的后面部分对此进行解释
。

318
00:18:34,290 --> 00:18:35,990
现在我将跳过它们。

319
00:18:35,990 --> 00:18:42,380
你也可以跳到视频中的那部分，
因为我会把视频的部分

320
00:18:42,380 --> 00:18:43,380
放在描述中。

321
00:18:43,380 --> 00:18:46,500
现在提示：这个很重要。

322
00:18:46,500 --> 00:18:53,840
实例提示用于定义
将激活

323
00:18:53,840 --> 00:18:56,440
我们教给模型的新主题的关键字。

324
00:18:56,440 --> 00:19:05,200
所以在这里你必须选择一个独特的词，
但它必须非常具体和罕见。

325
00:19:05,200 --> 00:19:07,179
无论你输入模型。

326
00:19:07,179 --> 00:19:10,110
他们将变成代币。

327
00:19:10,110 --> 00:19:11,900
他们将分裂成代币。

328
00:19:11,900 --> 00:19:15,280
所以有一个 reddit 线程解释了
稀有令牌。

329
00:19:15,280 --> 00:19:24,320
我将把这个页面的链接放到描述中，
这里列出了代币的稀有性。

330
00:19:24,320 --> 00:19:29,650
因此，例如，您输入了
mill。

331
00:19:29,650 --> 00:19:34,370
它是一个单一的令牌，但mill
在现实生活中可能存在很多。

332
00:19:34,370 --> 00:19:40,750
因此，你必须深入到底，
设法找到你无法理解的稀有令牌

333
00:19:40,750 --> 00:19:42,200
。

334
00:19:42,200 --> 00:19:43,940
比如，他们。

335
00:19:43,940 --> 00:19:49,280
此外，这些标记也应该用于其他
语言。

336
00:19:49,280 --> 00:19:57,620
例如，从这里：ohwx 是一个非常有名的
令牌，因为这是一个几乎

337
00:19:57,620 --> 00:19:59,960
在任何地方都不存在的令牌。

338
00:19:59,960 --> 00:20:06,380
当我在 Google 中输入 ohwx 时，您会看到所有
不相关的内容。

339
00:20:06,380 --> 00:20:07,760
它们看起来像垃圾邮件。

340
00:20:07,760 --> 00:20:14,020
所以这是一个很好的令牌，例如，
您也可以在这里尝试其他看起来很

341
00:20:14,020 --> 00:20:15,030
奇怪的令牌。

342
00:20:15,030 --> 00:20:16,140
也许这个？

343
00:20:16,140 --> 00:20:17,250
是的，这个，好的。

344
00:20:17,250 --> 00:20:27,049
我不确定这是否是真实姓名，
因此您可以验证它，但是 ohwx 非常

345
00:20:27,049 --> 00:20:31,190
好用，您选择的令牌非常重要。

346
00:20:31,190 --> 00:20:37,950
因为您的训练将从该
令牌开始，并且您可以注入

347
00:20:37,950 --> 00:20:44,350
数据库中不存在的新令牌，所以
您输入的所有内容都将成为一个令牌，它知道

348
00:20:44,350 --> 00:20:46,110
它们将被夹入其中。

349
00:20:46,110 --> 00:20:54,520
即使您生成一个新关键字，例如
SECourses，模型也不会将其视为

350
00:20:54,520 --> 00:20:55,780
SECourses。

351
00:20:55,780 --> 00:20:57,020
它会怎么看？

352
00:20:57,020 --> 00:21:01,440
首先它会查看 S 键、SE 键。

353
00:21:01,440 --> 00:21:03,890
所以 SE 密钥确实存在，好的。

354
00:21:03,890 --> 00:21:05,830
然后它会看起来秒。

355
00:21:05,830 --> 00:21:10,970
所以，是的，sec 也存在。

356
00:21:10,970 --> 00:21:12,250
然后它会看起来像山高。

357
00:21:12,250 --> 00:21:16,380
好的，没有 seco，所以它会被拆
分成 sec。

358
00:21:16,380 --> 00:21:23,960
然后它会检查
其他字符，剩余的字符，

359
00:21:23,960 --> 00:21:33,990
所以它们都会被拆分成 yes our SECourses
可能会变成 sec our ses 或

360
00:21:33,990 --> 00:21:34,990
类似的东西。

361
00:21:34,990 --> 00:21:35,990
你看，你明白了。

362
00:21:35,990 --> 00:21:37,190
我希望如此。

363
00:21:37,190 --> 00:21:44,650
因此，无论您输入
什么，您输入的关键字都会被拆分成标记。

364
00:21:44,650 --> 00:21:51,510
因此，我们
从这个列表中挑选了一个非常罕见的令牌，我做了

365
00:21:51,510 --> 00:21:52,510
很多测试。

366
00:21:52,510 --> 00:21:58,990
所以ohwx运行的很好然后我们需要
进入我们要教授的科目的班级

367
00:21:58,990 --> 00:21:59,990
。

368
00:21:59,990 --> 00:22:00,990
我要教什么？

369
00:22:00,990 --> 00:22:03,450
我要教我的脸。

370
00:22:03,450 --> 00:22:04,490
所以这是人的脸。

371
00:22:04,490 --> 00:22:07,309
因此，我只是进入人。

372
00:22:07,309 --> 00:22:09,400
所以这真的很重要。

373
00:22:09,400 --> 00:22:15,230
它将使用模型中人的基础知识
来学习我的脸。

374
00:22:15,230 --> 00:22:21,970
课堂提示：现在，正如我所说，这将
用于保持我们模型的完整性并防止

375
00:22:21,970 --> 00:22:22,970
过度训练。

376
00:22:22,970 --> 00:22:27,230
当您也悬停它时，它会说：阅读我以获取
更多信息。

377
00:22:27,230 --> 00:22:31,650
我想知道他们是否已添加到 wiki 中。

378
00:22:31,650 --> 00:22:33,780
也许在基础上？

379
00:22:33,780 --> 00:22:38,950
好的，在 wiki 中，在基础知识中他们有一个
小的解释。 还引入了

380
00:22:38,950 --> 00:22:44,840
特定于类的先验保存损失，
以防止过度拟合并

381
00:22:44,840 --> 00:22:49,340
鼓励生成
同一类的不同实例。

382
00:22:49,340 --> 00:22:51,700
他们做了一个这样的例子。

383
00:22:51,700 --> 00:22:55,510
所以在课堂提示中我要输入
男人的照片。

384
00:22:55,510 --> 00:23:00,110
好的，你看，这两个是相同的示例
提示。

385
00:23:00,110 --> 00:23:04,770
这将用于
在训练期间生成预览图像，因此我们将能够

386
00:23:04,770 --> 00:23:11,010
看到训练的进行情况以及训练
是否过度。

387
00:23:11,010 --> 00:23:15,210
所以在这里我要输入 ohwx man 的照片
。

388
00:23:15,210 --> 00:23:22,510
好的，我没有输入任何否定提示，
也没有使用任何示例提示模板。

389
00:23:22,510 --> 00:23:28,250
因此，比方说，这些是更高级的东西
，您也可以在

390
00:23:28,250 --> 00:23:30,400
学习了基础知识后使用它们。

391
00:23:30,400 --> 00:23:32,870
在这里，每个实例的类图像。

392
00:23:32,870 --> 00:23:39,799
在社区中，通常说
总共最少有 300 张图像。

393
00:23:39,799 --> 00:23:42,710
在 DreamBooth 的官方论文中。

394
00:23:42,710 --> 00:23:45,050
哪个在这里。

395
00:23:45,050 --> 00:23:48,990
我也会把这篇论文的链接放到
描述中。

396
00:23:48,990 --> 00:23:53,370
他们使用了 200 个分类图像。

397
00:23:53,370 --> 00:23:59,850
我做了一些测试，但我不能
确定需要多少最小值。

398
00:23:59,850 --> 00:24:06,570
所以我只是去关注社区
并达到我需要输入的 300 张图像，

399
00:24:06,570 --> 00:24:12,020
让我们轻松地计算 300 除以
训练图像的数量。

400
00:24:12,020 --> 00:24:14,260
我有12，所以25..

401
00:24:14,260 --> 00:24:16,190
你也可以这样计算。

402
00:24:16,190 --> 00:24:18,180
所以分类，CVG尺度。

403
00:24:18,180 --> 00:24:25,410
这个和text2images CFG scale how
many，你要用多少CFG scale来

404
00:24:25,410 --> 00:24:27,850
生成分类图像？

405
00:24:27,850 --> 00:24:32,580
顺便说一下，您还可以使用 text2image 选项卡
来生成分类图像。

406
00:24:32,580 --> 00:24:35,860
将它们放入我们在这里设置的文件夹中。

407
00:24:35,860 --> 00:24:40,730
然后扩展将不会生成任何新
图像。

408
00:24:40,730 --> 00:24:41,730
它是由你决定。

409
00:24:41,730 --> 00:24:47,570
这两种方式都可以使用，但是如果你使用
这种方式，它还会生成一个与

410
00:24:47,570 --> 00:24:54,700
图片名称相同的文本描述文件，并将
你在这里输入的描述放在里面。

411
00:24:54,700 --> 00:24:56,640
我稍后会展示。

412
00:24:56,640 --> 00:24:58,270
分类步骤。

413
00:24:58,270 --> 00:25:01,490
所以这是等于此处的步数
。

414
00:25:01,490 --> 00:25:05,630
采样步骤：确定，以及
要生成的样本数。

415
00:25:05,630 --> 00:25:10,990
所以这是我们希望
在训练过程中生成的样本数量，以查看

416
00:25:10,990 --> 00:25:12,770
训练进行得如何。

417
00:25:12,770 --> 00:25:15,659
您可以将其设置为 1、2、3、4，任何您
想要的。

418
00:25:15,659 --> 00:25:17,159
样本种子 -1。

419
00:25:17,159 --> 00:25:23,500
这意味着为样本生成的每个图像都
将随机不同，随机

420
00:25:23,500 --> 00:25:27,960
种子和样本 CFG 比例为 7.5。

421
00:25:27,960 --> 00:25:30,409
你不需要改变这个。

422
00:25:30,409 --> 00:25:32,460
这些与 text2image 相同。

423
00:25:32,460 --> 00:25:36,620
习惯了文本到图像后，您就会理解它
。

424
00:25:36,620 --> 00:25:45,399
好的，现在让我们回到这里：
我们希望同时并行生成多少张图像用于分类

425
00:25:45,399 --> 00:25:47,440
。

426
00:25:47,440 --> 00:25:50,340
所以我有 12 GB VRAM 内存。

427
00:25:50,340 --> 00:25:56,360
因此，我可以批量生成 10 张图像
，因此

428
00:25:56,360 --> 00:25:58,080
生成分类图像所需的时间会更少。

429
00:25:58,080 --> 00:26:06,250
顺便说一句，您只需要
为每个类提示生成一次分类图像。

430
00:26:06,250 --> 00:26:11,659
所以如果你不改变人的照片，如果你
不改变你的学科类别，那么

431
00:26:11,659 --> 00:26:14,279
你就不需要再次生成它们。

432
00:26:14,279 --> 00:26:20,380
因此，为了向您展示，我将其设置为
五个，您就会明白。

433
00:26:20,380 --> 00:26:24,170
它将生成图像，五张和五张作为
批次。

434
00:26:24,170 --> 00:26:25,170
好的。

435
00:26:25,170 --> 00:26:34,580
还有一件事：您一次最多可以向模型教授三个
概念。

436
00:26:34,580 --> 00:26:42,000
所以第一个概念是：假设是
我，在这里我也可以教我妻子画画

437
00:26:42,000 --> 00:26:43,000
。

438
00:26:43,000 --> 00:26:45,500
它可以像妻子 DB。

439
00:26:45,500 --> 00:26:52,559
所以另一个文件夹及其分类数据
集可以与另一个完全相同，

440
00:26:52,559 --> 00:26:55,909
或者不，它不会，因为它
与女性有关。

441
00:26:55,909 --> 00:26:59,440
因为这将是一个女人，而不是男人。

442
00:26:59,440 --> 00:27:06,610
因此，假设是女性图像，在
这里您需要为此使用另一个关键字。

443
00:27:06,610 --> 00:27:13,470
所以从这个列表中找到一个罕见的关键字很重要
。

444
00:27:13,470 --> 00:27:21,990
我不知道哪些是非常罕见的，但
ske 通常用于另一个提示。

445
00:27:21,990 --> 00:27:26,800
所以它可以像一个ske女人。

446
00:27:26,800 --> 00:27:38,100
在这里，它将是一张女性照片，
样本将是一张 ske 女性的照片。

447
00:27:38,100 --> 00:27:40,660
好的，其余的都是一样的。

448
00:27:40,660 --> 00:27:43,159
您还可以在此处添加另一个概念。

449
00:27:43,159 --> 00:27:50,789
但唯一重要的是
另一个主题的类别，如果是的话。

450
00:27:50,789 --> 00:27:59,240
如果它是一只猫、一只狗或一棵树，无论
你在教什么类和实例提示，

451
00:27:59,240 --> 00:28:05,030
这样你就可以用不同的方式称呼它们，
你可以在一张图片中同时使用它们。

452
00:28:05,030 --> 00:28:09,620
例如，您可以
在同一张照片中生成您妻子和您自己的照片，

453
00:28:09,620 --> 00:28:12,610
或者您的狗和您自己在同一张照片中的照片。

454
00:28:12,610 --> 00:28:18,330
但是对于本教程，我不会教
多个概念，所以教

455
00:28:18,330 --> 00:28:19,330
与不教由你决定。

456
00:28:19,330 --> 00:28:23,549
我只会教一个概念。

457
00:28:23,549 --> 00:28:24,549
好的。

458
00:28:24,549 --> 00:28:27,860
现在我们要转到保存选项卡。

459
00:28:27,860 --> 00:28:33,150
在这里您可以输入自定义模型名称
以保存检查点和 LoRA 模型。

460
00:28:33,150 --> 00:28:34,669
你可以看看半模型。

461
00:28:34,669 --> 00:28:41,480
他们说这不会降低质量，
但检查点会变小。

462
00:28:41,480 --> 00:28:46,330
我没有测试它，所以我不能说它是否 100
% 正确。

463
00:28:46,330 --> 00:28:51,760
所以为了保持最大的质量，我不会检查
它。

464
00:28:51,760 --> 00:28:53,279
将检查点保存到子目录。

465
00:28:53,279 --> 00:28:55,210
你应该做这个。

466
00:28:55,210 --> 00:29:01,700
您应该选中此复选框，以便
节省将在 Web UI ohwx 下显示。

467
00:29:01,700 --> 00:29:04,190
他们不会进入同一个目录。

468
00:29:04,190 --> 00:29:06,710
现在这很重要。 在

469
00:29:06,710 --> 00:29:10,580
训练期间保存时生成一个 ckpt 文件。

470
00:29:10,580 --> 00:29:17,220
如果你不检查这个，那么假设你将
无法

471
00:29:17,220 --> 00:29:22,659
在第 20 个纪元或第 40 个纪元或第 60 个
纪元时测试、加载和测试模型。

472
00:29:22,659 --> 00:29:24,360
所以你应该检查一下。

473
00:29:24,360 --> 00:29:27,830
您也可以从该点继续使用
它作为基本模式。

474
00:29:27,830 --> 00:29:35,279
您还可以加载该模型，然后
对其进行测试推理。

475
00:29:35,279 --> 00:29:40,899
所以这很重要，但这会增加
你的硬盘使用率。

476
00:29:40,899 --> 00:29:41,899
小心点。

477
00:29:41,899 --> 00:29:43,549
训练完成后生成一个 ckpt 文件。

478
00:29:43,549 --> 00:29:44,549
是的。

479
00:29:44,549 --> 00:29:46,720
取消训练时生成 ckpt 文件。

480
00:29:46,720 --> 00:29:53,510
我没有检查这个，因为当我取消时
我不希望它生成一个 ckpt。

481
00:29:53,510 --> 00:29:58,390
取消后，您只需加载模型
并单击 ckpt，它将

482
00:29:58,390 --> 00:30:00,799
根据上次保存的权重生成一个 ckpt 文件。

483
00:30:00,799 --> 00:30:02,259
现在称重。

484
00:30:02,259 --> 00:30:08,230
您会看到在训练期间保存时还有一个选项可以保存单独的
漫射器快照。

485
00:30:08,230 --> 00:30:14,950
此选项将生成权重文件，如
您在此处看到的那样。

486
00:30:14,950 --> 00:30:21,980
因此，出于演示目的，我还将在
稍后选择它，您可以

487
00:30:21,980 --> 00:30:27,840
将它们作为一个新的模型文件夹，然后您
可以从那里继续您的培训。

488
00:30:27,840 --> 00:30:35,380
或者，我相信您可以
从保存的 ckpt 文件生成一个新模型作为

489
00:30:35,380 --> 00:30:41,160
新的源检查点，然后您可以
从保存的检查点 ckpt 文件继续。

490
00:30:41,160 --> 00:30:44,070
我认为两者应该相同。

491
00:30:44,070 --> 00:30:45,760
好的。

492
00:30:45,760 --> 00:30:48,220
完成设置后，只需单击保存设置。

493
00:30:48,220 --> 00:30:51,610
当你点击火车时，我认为它
也会自动保存。

494
00:30:51,610 --> 00:30:56,130
现在我将在开始训练之前生成类图像
。

495
00:30:56,130 --> 00:31:02,410
这将使用我
在这些选项中设置的设置。

496
00:31:02,410 --> 00:31:05,720
让我们看看我们
将获得什么样的类图像。

497
00:31:05,720 --> 00:31:10,340
好的，你看，它正在生成 300 个类
图像用于训练。

498
00:31:10,340 --> 00:31:11,340
为什么？

499
00:31:11,340 --> 00:31:18,909
因为目前我这里没有图像，
但是，如您所见，它现在无法正常工作

500
00:31:18,909 --> 00:31:19,909
。

501
00:31:19,909 --> 00:31:20,980
所以有一个错误。

502
00:31:20,980 --> 00:31:25,549
显然，为了解决这个错误，我将重新
启动应用程序。

503
00:31:25,549 --> 00:31:28,190
OK，重启完成。

504
00:31:28,190 --> 00:31:29,190
让我们刷新一下。

505
00:31:29,190 --> 00:31:32,020
返回我们的扩展选项卡。

506
00:31:32,020 --> 00:31:33,020
检查更新。

507
00:31:33,020 --> 00:31:34,309
如果有更新。

508
00:31:34,309 --> 00:31:38,519
是的，视频中有新的更新。

509
00:31:38,519 --> 00:31:41,389
更新即将到来，所以让我们刷新一下。

510
00:31:41,389 --> 00:31:43,330
好的，精神焕发。

511
00:31:43,330 --> 00:31:44,550
让我们回到扩展。

512
00:31:44,550 --> 00:31:45,550
检查更新。

513
00:31:45,550 --> 00:31:46,550
好的，我们在最后。

514
00:31:46,550 --> 00:31:52,490
然后我们去 DreamBooth，选择我们的模型
加载设置。

515
00:31:52,490 --> 00:31:54,649
去生成。

516
00:31:54,649 --> 00:31:59,490
在生成之前，我会先删除这些不正确的
图像。

517
00:31:59,490 --> 00:32:00,490
让我这样做。

518
00:32:00,490 --> 00:32:07,169
转到图片并在此处转到
Web UI 教程。

519
00:32:07,169 --> 00:32:08,980
Ctrl-a shift-删除。

520
00:32:08,980 --> 00:32:11,040
对，都删了。

521
00:32:11,040 --> 00:32:13,760
只需单击生成类图像。

522
00:32:13,760 --> 00:32:16,170
OK，再看看有没有报错。

523
00:32:16,170 --> 00:32:20,970
好的，好的，我认为错误仍然存​​在。

524
00:32:20,970 --> 00:32:27,040
因此，我将不使用这些方法，而是使用 txt2image
选项卡来生成图像。

525
00:32:27,040 --> 00:32:33,100
这些与使用
文本到图像之间的唯一区别是：让我告诉你。

526
00:32:33,100 --> 00:32:37,230
同时，让我们重新启动应用程序。

527
00:32:37,230 --> 00:32:44,760
使用时，像这样生成图片也会
生成一个文本文件，与

528
00:32:44,760 --> 00:32:51,529
图片名称同名，里面会写
上人的照片作为描述。

529
00:32:51,529 --> 00:33:00,010
所以这在你做 [filewords]
训练或者当你做 LoRA 训练时很有用，但

530
00:33:00,010 --> 00:33:04,929
现在对我们来说没有必要。

531
00:33:04,929 --> 00:33:11,700
我刚刚也向开发人员报告了这个错误，
所以我相信它会很快得到修复。

532
00:33:11,700 --> 00:33:19,110
好的，所以我们将从这里生成我们的类
图像。

533
00:33:19,110 --> 00:33:21,169
分类图像：人的照片。

534
00:33:21,169 --> 00:33:26,270
我只是输入设置采样
步数为 40，设置 CFG：7.5。

535
00:33:26,270 --> 00:33:35,260
所以这个批量大小意味着
在同一个时期处理多个图像。

536
00:33:35,260 --> 00:33:39,010
它会使用更多的 GPU 内存，但会使其
更快。

537
00:33:39,010 --> 00:33:40,330
我需要多少？

538
00:33:40,330 --> 00:33:41,850
我需要 300。

539
00:33:41,850 --> 00:33:50,640
因此，我将把它设置为 38，像
这样，然后单击生成。

540
00:33:50,640 --> 00:33:52,880
所以现在它会生成图像。

541
00:33:52,880 --> 00:34:00,340
但请确保您在此处看到的所选模型与
您

542
00:34:00,340 --> 00:34:02,659
用于生成模型的模型相同。

543
00:34:02,659 --> 00:34:08,290
所以在这里，当您选择要
训练的模型时，它会显示基本模型源检查点。

544
00:34:08,290 --> 00:34:14,820
您会看到 Stable Diffusion 1.5 已修剪，目前
我正在从该模型生成相同的图像。

545
00:34:14,820 --> 00:34:20,010
因此生成的图像将以文本形式保存到
图像文件夹中。

546
00:34:20,010 --> 00:34:22,340
让我们点击这里打开它。

547
00:34:22,340 --> 00:34:27,879
好的，当我在这里点击打开文件夹时。

548
00:34:27,879 --> 00:34:34,139
它没有打开，因为它在 CMD 窗口中说
：文本到图像图像不存在。

549
00:34:34,139 --> 00:34:35,139
创建图像后。

550
00:34:35,139 --> 00:34:40,050
它将生成，因为正如我所说，这
是一个全新的安装来向您展示。

551
00:34:40,050 --> 00:34:42,810
因此，我这里的所有设置也是
默认的。

552
00:34:42,810 --> 00:34:46,070
我没有改变他们中的任何一个。

553
00:34:46,070 --> 00:34:48,329
还有一件事我想
提一下。

554
00:34:48,329 --> 00:34:56,609
在 DreamBooth 模型选择中，您将
在 SD 1.x 版本中看到它们

555
00:34:56,609 --> 00:34:57,859
是否具有 EMA。

556
00:34:57,859 --> 00:35:05,300
所以如果他们有 EMA，它会增加你的
进一步训练，微调模型。

557
00:35:05,300 --> 00:35:09,130
所以你应该选择有模型的 EMA 版本。

558
00:35:09,130 --> 00:35:11,580
它仅存在于 1.x 版本中。

559
00:35:11,580 --> 00:35:14,260
我认为在 SD 2.0 中。

560
00:35:14,260 --> 00:35:20,329
在 2.1 中没有发布的模型
具有 EMA 功能。

561
00:35:20,329 --> 00:35:22,990
OK，第一批已经完成。

562
00:35:22,990 --> 00:35:23,990
让我们打开文件夹。

563
00:35:23,990 --> 00:35:26,400
现在文件夹已打开。

564
00:35:26,400 --> 00:35:28,859
所以这些是男人的照片。

565
00:35:28,859 --> 00:35:33,869
你看，会有非常奇怪的图像，
质量很差的图像，但它们并不重要

566
00:35:33,869 --> 00:35:34,869
。

567
00:35:34,869 --> 00:35:40,310
只要它们
是由我们的检查点模型生成的，它们就不是很重要。

568
00:35:40,310 --> 00:35:48,240
好的，在生成所有图像后，
只需使用 control-C 将它们全部选中，然后

569
00:35:48,240 --> 00:35:54,740
返回到您要
保存它们的文件夹 web UI 教程。

570
00:35:54,740 --> 00:35:58,880
我只是将它们复制粘贴到
文件夹中。

571
00:35:58,880 --> 00:36:04,170
好的，让我们回到我们的 DreamBooth 并
加载设置。

572
00:36:04,170 --> 00:36:09,079
所以现在我们有足够数量的分类
图像。

573
00:36:09,079 --> 00:36:12,210
现在我们准备好点击开始训练了。

574
00:36:12,210 --> 00:36:19,900
好的，当我们开始训练时，它会首先
从缓存它们开始。

575
00:36:19,900 --> 00:36:23,700
我们会看到的。

576
00:36:23,700 --> 00:36:28,500
所以你看，它说它已经找到了 300 个
正则化图像。

577
00:36:28,500 --> 00:36:32,440
因此，它不会再生成任何
图像。

578
00:36:32,440 --> 00:36:35,849
目前它正在缓存它们。

579
00:36:35,849 --> 00:36:42,340
OK，缓存完成后，
你会看到训练已经开始了。

580
00:36:42,340 --> 00:36:45,800
它正在一步步推进。

581
00:36:45,800 --> 00:36:48,460
您会看到 13、14。

582
00:36:48,460 --> 00:36:55,069
如果出现内存不足错误，则需要
尝试进一步降低内存使用量。

583
00:36:55,069 --> 00:37:01,839
所有低内存设置和高内存
设置都在 wiki 中说明。

584
00:37:01,839 --> 00:37:03,640
我会把这个放到描述中。

585
00:37:03,640 --> 00:37:05,420
另外，你现在看到了。

586
00:37:05,420 --> 00:37:08,200
批量大小高，设置梯度。

587
00:37:08,200 --> 00:37:13,170
这些将增加您的内存使用量，而
这些将减少您的内存使用量。

588
00:37:13,170 --> 00:37:18,400
您
无能为力，另一件事是开发人员

589
00:37:18,400 --> 00:37:26,089
不断尝试优化和改进
扩展以减少内存使用。

590
00:37:26,089 --> 00:37:33,860
因此，当您观看此视频时，或者
一个月后，您，您的卡片，

591
00:37:33,860 --> 00:37:37,940
也许可以使用 DreamBooth 培训。

592
00:37:37,940 --> 00:37:41,140
所以这是另一种可能性。 在

593
00:37:41,140 --> 00:37:45,599
多少步之后我们将看到
我们的第一个示例图像？

594
00:37:45,599 --> 00:37:47,130
我们可以很容易地计算出来。

595
00:37:47,130 --> 00:37:49,480
在设置选项卡中。

596
00:37:49,480 --> 00:37:53,240
我们确实设置了 10 个 epoch 以及
我们有多少训练图像。

597
00:37:53,240 --> 00:37:56,000
我们有 12 个，你看这里。

598
00:37:56,000 --> 00:38:05,119
因此，在 120 步之后，我们将
看到我们的第一个样本训练样本图像。

599
00:38:05,119 --> 00:38:12,240
实际上，在 120 步之后，它会保存
检查点。

600
00:38:12,240 --> 00:38:15,339
60步之后，因为我们确实设置了5个epochs。

601
00:38:15,339 --> 00:38:20,590
我们将看到第一个示例图像，
60 个步骤已经完成。

602
00:38:20,590 --> 00:38:24,040
所以它在第 60 步生成预览图像。


603
00:38:24,040 --> 00:38:28,130
好的，第一个样本已经生成。

604
00:38:28,130 --> 00:38:29,690
让我们打开示例文件夹。

605
00:38:29,690 --> 00:38:34,190
所以他们在哪里得救，他们就
在我们的模式下得救。

606
00:38:34,190 --> 00:38:41,250
让我展示一下：好的，我有很多相同的标签。

607
00:38:41,250 --> 00:38:47,020
好的，在我们的安装文件夹中，转到
模型，然后转到 DreamBooth

608
00:38:47,020 --> 00:38:50,890
，在这里您会看到与我们的训练模型名称相同的名称
。

609
00:38:50,890 --> 00:38:52,200
进入那里。

610
00:38:52,200 --> 00:38:53,880
在这里你会看到样品。

611
00:38:53,880 --> 00:38:56,700
当您单击此处时，您将看到示例。

612
00:38:56,700 --> 00:39:05,280
因此，第一个示例是
使用 ohwx man 使用此示例提示生成的。

613
00:39:05,280 --> 00:39:09,810
所以这是我们的班级，这是
我们设置的唯一实例提示。

614
00:39:09,810 --> 00:39:11,819
好的，所以还有另一个图像。

615
00:39:11,819 --> 00:39:12,819
你看。

616
00:39:12,819 --> 00:39:19,100
这是由 Tomer Hanuka 拍摄的 ohwx man 照片生成的
。

617
00:39:19,100 --> 00:39:22,380
我为什么要设置这个，我在哪里设置这个？

618
00:39:22,380 --> 00:39:24,400
我确实在这里设置了这个。

619
00:39:24,400 --> 00:39:35,109
如果您还记得的话，您在这里看到的第二个提示
是 sanity

620
00:39:35,109 --> 00:39:38,480
sample 提示。

621
00:39:38,480 --> 00:39:43,940
这里的数字是它
已经生成的步数，这是另一个

622
00:39:43,940 --> 00:39:47,180
用于生成它的提示。

623
00:39:47,180 --> 00:39:54,660
当我们在培训中取得进展后，您就会
明白我们为什么要使用它。 尽管

624
00:39:54,660 --> 00:40:00,600
这张图片看起来很像我们，但
风格不同，这意味着我们的模型

625
00:40:00,600 --> 00:40:07,210
学习得很好，当它变得
和我们一模一样，而不是这样的风格时，这

626
00:40:07,210 --> 00:40:12,089
意味着我们的模型训练过度，现在
我们不能 应用样式。

627
00:40:12,089 --> 00:40:22,640
我们的目标是学习我们教授我们的形状，
但不是过度训练它，不是分布，

628
00:40:22,640 --> 00:40:29,040
扰乱潜在的背景，
它的知识，而不是完全覆盖它。

629
00:40:29,040 --> 00:40:32,690
所以当我们在训练中取得进展后，我们会
更好地理解。

630
00:40:32,690 --> 00:40:40,590
好的，现在让我向您解释如何
准备训练数据集图像。 图像

631
00:40:40,590 --> 00:40:45,829
的选择有什么重要的
？

632
00:40:45,829 --> 00:40:50,569
我们想教的就是
我们想教的科目。

633
00:40:50,569 --> 00:40:52,170
最重要的部分。

634
00:40:52,170 --> 00:40:54,250
我想教我的脸。

635
00:40:54,250 --> 00:40:59,070
因此，除了我的脸，其他一切都
必须不同，或者说，

636
00:40:59,070 --> 00:41:01,080
每幅图像都应该不同。

637
00:41:01,080 --> 00:41:03,890
那么，除了脸，还能有什么不同呢？

638
00:41:03,890 --> 00:41:07,830
我的衣服和背景可以不同。

639
00:41:07,830 --> 00:41:14,240
所以如果你教的是脸以外的脸
，所有的背景和

640
00:41:14,240 --> 00:41:17,540
衣服都尽量不同。

641
00:41:17,540 --> 00:41:23,500
正如你在我的照片中看到的，我
确保所有的背景和衣服都

642
00:41:23,500 --> 00:41:27,740
不同，或者衣服是不可见的。

643
00:41:27,740 --> 00:41:34,030
所以如果你让你的衣服和
背景不同，那么模型

644
00:41:34,030 --> 00:41:37,640
会学习你的脸，而不是你的衣服或
背景。

645
00:41:37,640 --> 00:41:38,650
这就是我们想要的。

646
00:41:38,650 --> 00:41:42,460
我们想教我们的脸，而不是
图片中的其他东西。

647
00:41:42,460 --> 00:41:49,650
如果你使用相同的衣服，那么模特
不会说这是脸，这是

648
00:41:49,650 --> 00:41:53,530
衣服，模特会
同时学习这两种衣服，这会减少

649
00:41:53,530 --> 00:41:57,060
你对脸的风格化。

650
00:41:57,060 --> 00:42:04,560
因此，准备训练图像的关键
是要有与主题不同的东西

651
00:42:04,560 --> 00:42:05,560
。

652
00:42:05,560 --> 00:42:09,069
所以如果主题是脸，其他的东西
肯定不一样。

653
00:42:09,069 --> 00:42:18,010
另外，你应该有不同角度的
照片和不同距离的照片。

654
00:42:18,010 --> 00:42:25,540
它将使模型学习不同的角度
和不同的距离，以生成不同

655
00:42:25,540 --> 00:42:30,339
种类的不同风格、更多样的
图像。

656
00:42:30,339 --> 00:42:37,119
所以如果你做你的图像，我不能说我的
数据集是最好的可用数据集。

657
00:42:37,119 --> 00:42:42,730
您可以使用更多种类
的图像、更多种类的姿势、更多种类

658
00:42:42,730 --> 00:42:46,720
的角度、更多种类的闪电来扩展您的数据集。

659
00:42:46,720 --> 00:42:47,760
闪电也很重要。

660
00:42:47,760 --> 00:42:49,280
会更好。

661
00:42:49,280 --> 00:42:55,200
然而，这是一个小数据集，我认为
它工作得相当不错。

662
00:42:55,200 --> 00:43:00,520
但是如果你扩展这个数据集，你的训练
数据集，种类更多，那就更好了。

663
00:43:00,520 --> 00:43:08,000
它将以更普遍的方式学习你的脸或主题，
这样我们将

664
00:43:08,000 --> 00:43:14,410
能够更容易地产生不同类型的不同
艺术图像。

665
00:43:14,410 --> 00:43:21,880
好的，所以你看，目前它正在编译
一个检查点 ckpt 文件，你可以

666
00:43:21,880 --> 00:43:27,090
直接加载 ckpt 文件并在
该检查点上进行推理。

667
00:43:27,090 --> 00:43:34,770
它在第360步编译checkpoint，
也就是第30个epoch，那么这些

668
00:43:34,770 --> 00:43:37,130
checkpoint文件在哪呢？

669
00:43:37,130 --> 00:43:45,320
它们位于我们
文件夹内的模型上，您可以在此处看到 ckpt 文件和

670
00:43:45,320 --> 00:43:48,300
yaml 文件。

671
00:43:48,300 --> 00:43:55,609
如果您不知道什么是 yaml 文件，请
观看我

672
00:43:55,609 --> 00:43:59,359
在 Web UI 教程视频中如何使用 Stable Diffusion 2.1 和不同模型。

673
00:43:59,359 --> 00:44:07,940
我会像往常一样放链接，让我们
看看我们目前的样本。

674
00:44:07,940 --> 00:44:13,170
所以在这张图片中，这就像我一样，但没有其他
示例提示像我们一样。

675
00:44:13,170 --> 00:44:15,260
我们只需要做更多的训练。

676
00:44:15,260 --> 00:44:22,250
并且在此屏幕中您还会看到 5.5 或
3.7。

677
00:44:22,250 --> 00:44:30,540
所以这意味着这是
每秒完成多少次迭代。

678
00:44:30,540 --> 00:44:37,040
但是这些值显示的不是很正确
，所以也有损失，这个

679
00:44:37,040 --> 00:44:38,400
lr很重要。

680
00:44:38,400 --> 00:44:40,120
这显示了你的学习率。

681
00:44:40,120 --> 00:44:43,850
那么 2e-6 是什么意思？

682
00:44:43,850 --> 00:44:47,599
这意味着它是一个数字。 例如，

683
00:44:47,599 --> 00:44:54,119
当您将它输入到 google 2e-6 并
转到第一个结果时，它会

684
00:44:54,119 --> 00:44:57,339
告诉您它等于这个数字。

685
00:44:57,339 --> 00:44:58,980
好的，这就是数字。

686
00:44:58,980 --> 00:45:04,740
事实上，我们确实在我们的设置中设置了我们的
学习率，你看。

687
00:45:04,740 --> 00:45:10,190
所以这相当于科学的电子记
数法。

688
00:45:10,190 --> 00:45:17,280
如果你从这里设置变化的数字，你会
看到变化的数字，比如多项式、

689
00:45:17,280 --> 00:45:25,560
常数或其他东西，学习率，那么
你会在这里看到不同的数字，

690
00:45:25,560 --> 00:45:27,359
它还会显示 gpu 使用情况。

691
00:45:27,359 --> 00:45:30,720
然而，这也不是很准确。

692
00:45:30,720 --> 00:45:34,710
它说目前正在使用 9.5 GB
。

693
00:45:34,710 --> 00:45:41,160
好了好了，已经72、82个epoch了。

694
00:45:41,160 --> 00:45:46,730
现在我将向您展示如何
在发生错误时继续训练。

695
00:45:46,730 --> 00:45:51,440
因此，为了说明这一点，我将在
此处关闭时使应用程序崩溃。

696
00:45:51,440 --> 00:45:55,890
当你从这里关闭时，它不会保存任何
检查点或任何东西。

697
00:45:55,890 --> 00:45:58,360
使用错误连接错误。

698
00:45:58,360 --> 00:46:08,290
然后重新启动应用程序，
重新启动完成后，只需刷新界面即可。

699
00:46:08,290 --> 00:46:14,440
转到 DreamBooth 选项卡，选择模型，
单击加载设置它实际上会

700
00:46:14,440 --> 00:46:15,440
自动加载。

701
00:46:15,440 --> 00:46:17,500
然后只需单击火车。

702
00:46:17,500 --> 00:46:23,359
它将从最后一个检查点开始继续，
即 80 个纪元。

703
00:46:23,359 --> 00:46:25,140
我们等等吧。

704
00:46:25,140 --> 00:46:28,609
好的，你看到了。

705
00:46:28,609 --> 00:46:34,579
它从它离开的任何地方继续，
正如你在这里看到的那样。

706
00:46:34,579 --> 00:46:42,630
此外，在 cmd 窗口中，它显示了第一个恢复
纪元，然后是第一个恢复步骤，

707
00:46:42,630 --> 00:46:43,740
正如您在此处看到的那样。

708
00:46:43,740 --> 00:46:52,480
好的，我们已经超过 168 个 epoch，我们已经
进行了大量的过度训练。

709
00:46:52,480 --> 00:46:54,910
我怎么知道？

710
00:46:54,910 --> 00:47:03,619
正如我在开始时所说的那样，我已经进入了
理智，理智提示。

711
00:47:03,619 --> 00:47:09,950
因此，带有破折号编号的示例是
理智提示。

712
00:47:09,950 --> 00:47:12,830
让我们看看理智提示的变化。

713
00:47:12,830 --> 00:47:15,580
于是理智提示就这样开始了。

714
00:47:15,580 --> 00:47:23,310
然后在这里你看，理智提示
很像我，在这里也很像我，

715
00:47:23,310 --> 00:47:26,460
好吧，有点像我。 在

716
00:47:26,460 --> 00:47:37,660
某个点之后，实际上在 1368
步之后，理智提示变得和

717
00:47:37,660 --> 00:47:38,660
我一样。

718
00:47:38,660 --> 00:47:45,410
你看，它的风格不再像这样，像
这样，这几乎和

719
00:47:45,410 --> 00:47:50,089
我一样，你看，它们不再
像这里那样风格了。

720
00:47:50,089 --> 00:47:53,690
造型完全消失了，在这里。

721
00:47:53,690 --> 00:47:59,650
因此，现在我们确信我们正在做
过度训练。

722
00:47:59,650 --> 00:48:08,550
所以我将通过取消停止训练，
我将使用不同的检查点，

723
00:48:08,550 --> 00:48:11,710
测试它们以查看它们的表现。

724
00:48:11,710 --> 00:48:17,320
现在困难的部分来了：提示，
适当的，正确的提示以获得

725
00:48:17,320 --> 00:48:19,940
良好的结果。

726
00:48:19,940 --> 00:48:22,870
所以取消了培训。

727
00:48:22,870 --> 00:48:25,540
让我们寻找最近的一个。

728
00:48:25,540 --> 00:48:32,440
我在这里和这里刷新，是的，这个
看起来像最近的一个：1308。

729
00:48:32,440 --> 00:48:35,359
然后转到 text2image 选项卡。

730
00:48:35,359 --> 00:48:39,000
那么我们如何生成自己的图像呢？

731
00:48:39,000 --> 00:48:41,099
我们将使用的照片。

732
00:48:41,099 --> 00:48:47,290
这两个关键字现在也与我们相关联
，但不如我们的提示

733
00:48:47,290 --> 00:48:49,770
实例强大。

734
00:48:49,770 --> 00:48:50,770
Ohwx 和男人。

735
00:48:50,770 --> 00:48:57,690
人也是非常相关的，好吧，所以
当我们这样输入并点击生成

736
00:48:57,690 --> 00:49:00,099
按钮时，它会生成我们自己的图像。

737
00:49:00,099 --> 00:49:02,140
好的，图片准备好了。

738
00:49:02,140 --> 00:49:06,750
你看，它就像我们一样，现在我们需要
设计它。

739
00:49:06,750 --> 00:49:12,950
所以让我们添加这个名称样式，让我们
看看我们将获得什么样的结果。

740
00:49:12,950 --> 00:49:21,390
好的，如您所见，我们没有太多的
样式，因此，我将向

741
00:49:21,390 --> 00:49:26,380
您展示一个名为 web ui
提示生成器的扩展。

742
00:49:26,380 --> 00:49:29,130
您可以从可用选项卡安装它。

743
00:49:29,130 --> 00:49:34,150
只需单击加载，然后在此处搜索提示，
您将看到提示生成器，

744
00:49:34,150 --> 00:49:38,770
只需单击安装，然后应用并
重新启动 ui。

745
00:49:38,770 --> 00:49:41,340
之后，您将在此处看到提示生成器选项卡
。

746
00:49:41,340 --> 00:49:47,839
因此，让我们从提示生成器中获取一些额外的关键字，
然后单击生成。

747
00:49:47,839 --> 00:49:55,670
好的，这里有很多结果，但是，
我想到了这个，可以像这样工作，所以我将

748
00:49:55,670 --> 00:50:00,630
它复制并粘贴到这里，让我们看看
我们将要得到的结果。

749
00:50:00,630 --> 00:50:06,210
好吧，我们得到了一些不错的结果，但
它仍然不太像我们。

750
00:50:06,210 --> 00:50:10,920
因此，我们需要加大提示
力度。

751
00:50:10,920 --> 00:50:12,500
那么什么是瞬时强度呢？

752
00:50:12,500 --> 00:50:13,500
及时注意。

753
00:50:13,500 --> 00:50:17,380
这是来自 Automatic1111 的官方 wiki。

754
00:50:17,380 --> 00:50:24,750
因此，如果您想将对某个词的关注度提高
1.1，您可以将该词

755
00:50:24,750 --> 00:50:26,380
放在一个括号内。

756
00:50:26,380 --> 00:50:34,930
如果你想以
1.2、21 的倍数进一步增加注意力，那么你可以

757
00:50:34,930 --> 00:50:40,520
这样说：或者，你可以使用
更简单的方法，即：let me show

758
00:50:40,520 --> 00:50:47,010
me, let me also zoom in, just type 像这样：
好的，这样会增加注意力。

759
00:50:47,010 --> 00:50:56,470
这将迫使模型生成
更像我们的图像，并且它将忽略

760
00:50:56,470 --> 00:50:57,650
其余部分。

761
00:50:57,650 --> 00:51:05,130
此外，在这个提示中有很多与
迪士尼风格无关的东西。

762
00:51:05,130 --> 00:51:13,960
那么会和disney style相关的是什么，
比如CGI，我们也加一些

763
00:51:13,960 --> 00:51:15,049
其他的关键词。

764
00:51:15,049 --> 00:51:17,270
好的，这是结果。

765
00:51:17,270 --> 00:51:21,060
不太像我们，质量也不是很好。

766
00:51:21,060 --> 00:51:28,120
我们还需要通过添加
一些否定提示来改进提示。

767
00:51:28,120 --> 00:51:35,049
好吧，我在这里添加了一些负面提示，
现在你看到我们有更好的艺术作品，

768
00:51:35,049 --> 00:51:39,349
但仍然不太像我。

769
00:51:39,349 --> 00:51:47,640
因此，我将尝试另一个提示，同时
增加我们独特关键字的重点

770
00:51:47,640 --> 00:51:51,290
，即 ohwx 和 man。

771
00:51:51,290 --> 00:51:58,130
在每个提示中你必须有 ohwx man with
some increased strength，可能是为了得到你

772
00:51:58,130 --> 00:52:01,340
自己的脸，并且还添加了照片。

773
00:52:01,340 --> 00:52:02,340
为什么？

774
00:52:02,340 --> 00:52:09,059
因为在培训期间我们使用了课堂
提示作为人的照片。

775
00:52:09,059 --> 00:52:15,849
所以现在这三个关键词也
跟我们有关联，但是关联最多的

776
00:52:15,849 --> 00:52:18,890
还是ohwx，好吧。

777
00:52:18,890 --> 00:52:27,010
好的，所以我将尝试强调
1.5 和这样的新提示。

778
00:52:27,010 --> 00:52:28,260
让我们看看结果。

779
00:52:28,260 --> 00:52:32,859
好吧，我们得到了一张不太程式化的图像。

780
00:52:32,859 --> 00:52:35,370
因此，我们需要增加CFG。

781
00:52:35,370 --> 00:52:36,370
那么CFG是什么？

782
00:52:36,370 --> 00:52:43,020
CFG 是无分类器指导量表，
图像应符合提示的程度。

783
00:52:43,020 --> 00:52:45,130
较低的值会产生更具创意的结果。

784
00:52:45,130 --> 00:52:54,970
我们希望模型服从我们的提示，因为
我们提供了非常详细的提示。

785
00:52:54,970 --> 00:52:59,579
因此，我们需要扩大规模并进行尝试
。

786
00:52:59,579 --> 00:53:04,530
所以我将向您展示如何尝试多个
比例值。

787
00:53:04,530 --> 00:53:09,690
转到此处的底部并转到 x/y
图。

788
00:53:09,690 --> 00:53:14,190
所以在 x/y 图中有 x 和 y 值。

789
00:53:14,190 --> 00:53:15,720
目前我们只需要 x 值。

790
00:53:15,720 --> 00:53:22,150
在 x 值中，我将选择 CFG 比例，
在这里我只输入七、八、

791
00:53:22,150 --> 00:53:29,700
九、十、十一、十二、十三、十四、
十五、十六，我想

792
00:53:29,700 --> 00:53:37,869
对所有输入使用相同的种子 这样我就可以看到
变化，并且我将

793
00:53:37,869 --> 00:53:42,240
在每个迭代中的每个步骤中生成四个图像。

794
00:53:42,240 --> 00:53:45,319
我的图形卡能够处理四张图像。

795
00:53:45,319 --> 00:53:48,609
如果你没有太多的 vram，你就不能
这样做。

796
00:53:48,609 --> 00:53:50,990
那你应该增加这个。

797
00:53:50,990 --> 00:53:54,510
好吧，如果你检查这个，请为种子保留负一
。

798
00:53:54,510 --> 00:53:58,770
那么每一代中的每个图像都会
不同。

799
00:53:58,770 --> 00:54:04,520
但是，我想看看
图例中CFG效果的不同。

800
00:54:04,520 --> 00:54:09,650
因此，我保持这样，然后
单击生成。

801
00:54:09,650 --> 00:54:19,260
所以目前，在 CMD 窗口中，实际上
它在每个 epoch 生成四张图像。

802
00:54:19,260 --> 00:54:23,380
所以你看，在20个步骤中，实际上是在
处理80个步骤。

803
00:54:23,380 --> 00:54:32,480
所以其中四个正在并行处理，
因为我确实将批量大小设置为四。

804
00:54:32,480 --> 00:54:33,590
好的，CFG图像。

805
00:54:33,590 --> 00:54:35,760
生成了不同的 CFG 图像。

806
00:54:35,760 --> 00:54:40,910
我已经修改了输入，因为之前的
输入不太好。

807
00:54:40,910 --> 00:54:42,930
事实上，事实证明。

808
00:54:42,930 --> 00:54:47,869
但这并不重要，因为当你
使用 Stable Diffusion 时，你

809
00:54:47,869 --> 00:54:55,340
必须制作，你必须生成大量图像
以找出你想要获得的好图像

810
00:54:55,340 --> 00:54:57,619
。

811
00:54:57,619 --> 00:55:01,990
那么我们来看看，看看CFG的效果
。

812
00:55:01,990 --> 00:55:04,920
所以这是我们的种子值。

813
00:55:04,920 --> 00:55:11,960
如果你使用这个种子值，你将总是
在每一代中生成相似的图像，

814
00:55:11,960 --> 00:55:16,359
只要你保持相同的值，相同的模型。

815
00:55:16,359 --> 00:55:18,369
所以这是 CFG 规模七。

816
00:55:18,369 --> 00:55:23,710
在 CFG 等级 7 上，没有太多
相似之处。

817
00:55:23,710 --> 00:55:28,220
在 CFG 等级 8 上，有点相似。

818
00:55:28,220 --> 00:55:31,220
看看图像是如何变化的。

819
00:55:31,220 --> 00:55:33,819
这是 CFG 等级九。

820
00:55:33,819 --> 00:55:36,390
这两者有一些相似之处。

821
00:55:36,390 --> 00:55:39,480
好的，如果在 CFG 比例 10 中。

822
00:55:39,480 --> 00:55:47,119
现在，这也有些相似，在这里，
好吧，你看，相似在增加，

823
00:55:47,119 --> 00:55:53,510
实际上在 CFG 比例 14 中，
这个图像和这个

824
00:55:53,510 --> 00:56:00,280
图像实际上非常相似 , 就这样，在
一定的 CFG 规模之后，我认为

825
00:56:00,280 --> 00:56:03,400
质量开始下降。

826
00:56:03,400 --> 00:56:06,940
因此，CFG 规模有所不同。

827
00:56:06,940 --> 00:56:14,589
现在假设您想要测试
具有不同 CFG 比例的不同艺术家、风格。

828
00:56:14,589 --> 00:56:17,140
你怎么能那样做？

829
00:56:17,140 --> 00:56:23,670
我在这里放了一个特殊的关键字，我
将通过 replace kw 使用它。

830
00:56:23,670 --> 00:56:30,299
好的，剩下的就是你想要的任何东西，
在底部所以这次我要

831
00:56:30,299 --> 00:56:33,540
选择提示sr。

832
00:56:33,540 --> 00:56:39,180
好的，所以提示 sr 用作用
逗号分隔的单词列表，第一个单词

833
00:56:39,180 --> 00:56:40,590
将用作关键字。

834
00:56:40,590 --> 00:56:45,359
脚本将在提示中搜索该词
并将其替换为其他词。

835
00:56:45,359 --> 00:56:49,069
因此，无论我在此处键入什么，这些关键字都将被替换
。

836
00:56:49,069 --> 00:56:57,980
因此，让我们说 wlob，然后是 artgerm，然后是
您想测试的任何其他艺术家。

837
00:56:57,980 --> 00:57:02,630
好的，我又添加了两位艺术家，所以我们
有四位艺术家。

838
00:57:02,630 --> 00:57:10,400
让我们也测试 4 个 CFG 值 10、11、12 和
13。

839
00:57:10,400 --> 00:57:23,869
也许让我们从 11 开始，好吧，让我们
保留负一的种子，但那时

840
00:57:23,869 --> 00:57:27,390
我们无法测试 CFG 或样式。

841
00:57:27,390 --> 00:57:34,460
因此，让我们保持相同的种子，好吧，
你看，有恢复面孔、平铺

842
00:57:34,460 --> 00:57:40,270
和高分辨率修复，所以你也可以选择它们
来提高你的输出，但这会花费

843
00:57:40,270 --> 00:57:45,930
额外的时间，你可以在额外的地方做
我将显示的选项卡。

844
00:57:45,930 --> 00:57:48,309
批次计数为一，批次大小
为四。

845
00:57:48,309 --> 00:57:50,990
让我们看看我们将得到什么样的结果
。

846
00:57:50,990 --> 00:57:56,750
顺便说一句，这些其他关键字也会
严重影响艺术家的风格。

847
00:57:56,750 --> 00:58:03,220
因此，如果您只想查看
艺术家风格，那么您应该减少

848
00:58:03,220 --> 00:58:08,750
此处额外关键字的数量，让我们看看
我们将得到什么。

849
00:58:08,750 --> 00:58:11,580
好的，我确实遇到了运行时错误。

850
00:58:11,580 --> 00:58:12,580
为什么？

851
00:58:12,580 --> 00:58:16,190
因为我忘了把这个关键字
放在这里。

852
00:58:16,190 --> 00:58:18,330
第一个关键字必须是那个。

853
00:58:18,330 --> 00:58:20,880
现在我需要再次运行。

854
00:58:20,880 --> 00:58:23,819
好的，现在一代开始了。

855
00:58:23,819 --> 00:58:28,910
您应该始终检查 CMD 窗口
以及此处发生的情况。

856
00:58:28,910 --> 00:58:32,300
如果你得到一个错误，那么你显然应该修复它
。

857
00:58:32,300 --> 00:58:35,930
好的，这就是我们要得到的那种瓷砖
。

858
00:58:35,930 --> 00:58:37,710
实际上，它非常有用。

859
00:58:37,710 --> 00:58:45,551
所以，你看，在顶部的 CFG 比例尺和
左侧，我们得到了艺术风格，顺便说一下：它还

860
00:58:45,551 --> 00:58:56,010
产生了结果：replacekw 并且
不太像代表风格或我。

861
00:58:56,010 --> 00:59:07,650
因此，也许我们可以删除许多
会带走样式的关键字，例如：

862
00:59:07,650 --> 00:59:10,180
let me do。

863
00:59:10,180 --> 00:59:17,349
好的，这次我们有更多样式，
正如您在这里看到的：这是默认设置，

864
00:59:17,349 --> 00:59:21,859
这是 wlobe，这是 artgerm。

865
00:59:21,859 --> 00:59:25,290
这是 Robert S Duncanson，这是 Karol
Bak。

866
00:59:25,290 --> 00:59:31,950
正如您所见，尤其是 Karol Bak 的风格非常不同
且意义重大。

867
00:59:31,950 --> 00:59:38,030
所以这里的关键点是，使用 Stable Diffusion，
你必须生成大量图像，其中

868
00:59:38,030 --> 00:59:44,250
一些会非常非常好，但
可能大多数都不

869
00:59:44,250 --> 00:59:45,250
好用。

870
00:59:45,250 --> 00:59:55,470
这是基于 AI 的艺术生成的本质，
特别是如果你试图

871
00:59:55,470 --> 01:00:04,119
根据你的主题生成艺术，一个新的主题，
而且当我们在这里进行训练时，

872
01:00:04,119 --> 01:00:08,109
你可以使用更多的分类图像。

873
01:00:08,109 --> 01:00:09,990
那会有所帮助。

874
01:00:09,990 --> 01:00:18,730
我说过社区总共使用 300 个，
但这不是硬性限制。

875
01:00:18,730 --> 01:00:25,579
每个训练图像只能使用 200 张图像，
这可能会帮助您改进

876
01:00:25,579 --> 01:00:26,579
风格。

877
01:00:26,579 --> 01:00:30,700
实际上，
正如我所说，这也是官方文件中使用的数字。

878
01:00:30,700 --> 01:00:31,700
所以这取决于你。

879
01:00:31,700 --> 01:00:33,620
你必须做实验。

880
01:00:33,620 --> 01:00:39,369
您获得的数字和质量也完全
取决于您的训练数据集。 正如我所解释的那样，

881
01:00:39,369 --> 01:00:47,210
如果您拥有多种训练
数据集，那么您的模型

882
01:00:47,210 --> 01:00:49,030
可以学习得更好。

883
01:00:49,030 --> 01:00:50,910
我将在这里向您展示另一件事。

884
01:00:50,910 --> 01:00:57,049
有一个提示矩阵将生成
图像组合。

885
01:00:57,049 --> 01:01:05,280
好的，所以当你像这样输入你的查询
并从矩阵中选择它时，这个查询将

886
01:01:05,280 --> 01:01:10,260
变成 ohwx man:1.3 的面部照片，就像这样。

887
01:01:10,260 --> 01:01:15,370
然后他们会像这样结合起来。

888
01:01:15,370 --> 01:01:24,030
所以这将生成所有
书面文本的组合，让

889
01:01:24,030 --> 01:01:28,579
我再告诉你一次，垂直管道字符。

890
01:01:28,579 --> 01:01:32,530
它将像这样生成所有这些关键字组合
。

891
01:01:32,530 --> 01:01:34,580
好的，我会展示另一件事。

892
01:01:34,580 --> 01:01:40,450
假设您要睡觉了，您希望
计算机

893
01:01:40,450 --> 01:01:44,240
在您睡觉时为您生成许多不同风格的图像。

894
01:01:44,240 --> 01:01:49,289
为此，我将向您展示一种简单的方法
。

895
01:01:49,289 --> 01:01:58,890
所以我们的第一个提示是
ohwx 的面部照片，假设是 1.4。

896
01:01:58,890 --> 01:02:06,059
然后让我们添加一些特定的关键字来获得
某种提示。

897
01:02:06,059 --> 01:02:14,010
好的，我已经这样输入并生成了
20 个这样的输入，然后它为

898
01:02:14,010 --> 01:02:15,609
我生成了很多结果。

899
01:02:15,609 --> 01:02:23,940
我将把所有这些复制到一个记事本
文件中，粘贴它，这样你就会看到它们实际上是

900
01:02:23,940 --> 01:02:26,100
一行一行地复制的。

901
01:02:26,100 --> 01:02:28,450
然后我会生成更多。

902
01:02:28,450 --> 01:02:35,240
好的，我继续复制，将新生成的
输入粘贴到那里。

903
01:02:35,240 --> 01:02:40,360
好的，现在我有 60 行这样的输入。

904
01:02:40,360 --> 01:02:45,940
我要把它另存为。

905
01:02:45,940 --> 01:02:49,380
让我们转到图片和夜间提示。

906
01:02:49,380 --> 01:03:00,270
好的，然后返回到 text2img 选项卡，并在
此处从文件或文本框中选择提示。

907
01:03:00,270 --> 01:03:05,640
您可以将它们全部粘贴到此处，也可以
从此处上传。

908
01:03:05,640 --> 01:03:13,720
所以我会上传它们，从文本框，
从文本文件，它们都被上传了。

909
01:03:13,720 --> 01:03:19,920
我要说的是，对所有行使用随机种子
，因为我想获得尽可能多的

910
01:03:19,920 --> 01:03:22,329
不同结果。

911
01:03:22,329 --> 01:03:29,339
然后我想生成
你想要为每个图像生成多少图像。

912
01:03:29,339 --> 01:03:36,339
我想并行生成八张图像
，目前它们将使用

913
01:03:36,339 --> 01:03:39,490
我将在此处设置的 CFG 值 14。

914
01:03:39,490 --> 01:03:48,599
因此，对于 60 和 8 张图像的批量大小，我们
将获得 480 张图像。

915
01:03:48,599 --> 01:03:53,260
假设您想生成 4000 或任何
您想要的。

916
01:03:53,260 --> 01:04:02,720
所以如果我设置这个 20，我们将得到恰好
20 乘以 8 再乘以

917
01:04:02,720 --> 01:04:05,750
我们拥有的行数。

918
01:04:05,750 --> 01:04:13,700
夜间有 9600 张图像，有很多
不同的输入、变化，

919
01:04:13,700 --> 01:04:17,890
你可以从中挑选你想要的任何东西，随心所欲地使用它
。

920
01:04:17,890 --> 01:04:20,609
这是您可以选择的选项之一。

921
01:04:20,609 --> 01:04:25,279
好的，我点击它后，它开始生成
图像。

922
01:04:25,279 --> 01:04:31,910
例如，生成这个，如果你
想知道这个图像是什么，你可以转到 png

923
01:04:31,910 --> 01:04:39,950
信息，然后你可以去获取图像，将
它拖放到这里，它会显示

924
01:04:39,950 --> 01:04:42,500
它的所有参数 .

925
01:04:42,500 --> 01:04:47,549
所以这是提示输入，这是
它具有的否定提示输入和

926
01:04:47,549 --> 01:04:48,980
使用的步骤数。

927
01:04:48,980 --> 01:04:55,609
使用的采样器，使用的 CFG 尺度，
种子，所以使用这个种子你可以重复

928
01:04:55,609 --> 01:04:57,309
生成这个图像。

929
01:04:57,309 --> 01:05:02,940
您可以使用此种子并更改 CFG 值
并生成此值的其他变体以及

930
01:05:02,940 --> 01:05:04,750
大小和模型哈希。

931
01:05:04,750 --> 01:05:10,390
当然，模型哈希会发生变化，因为
我们使用的是自定义训练模型。

932
01:05:10,390 --> 01:05:15,090
批量大小和批量位置，所以
这也很重要。

933
01:05:15,090 --> 01:05:23,039
为了准确地得到这个，你需要生成
一个 against batch size 为 8，第六个位置

934
01:05:23,039 --> 01:05:24,039
就是这个。

935
01:05:24,039 --> 01:05:28,910
如果你使用这个种子和这个 CFG 值以及
这个采样器。

936
01:05:28,910 --> 01:05:34,130
我们得到了一些不错的照片，我会
让它在我睡觉的时候运行，明天

937
01:05:34,130 --> 01:05:38,700
我会向你展示，当然，稍后会为
你展示。

938
01:05:38,700 --> 01:05:43,080
我们将看看我们得到了什么样的好图像
。

939
01:05:43,080 --> 01:05:49,220
好吧，你看，我
在睡觉时生成的一些图像。

940
01:05:49,220 --> 01:05:52,320
它们的质量非常好，但它们
非常相似。

941
01:05:52,320 --> 01:05:53,320
为什么？

942
01:05:53,320 --> 01:05:59,829
因为看起来我
用来生成它们的输入并没有太大不同。

943
01:05:59,829 --> 01:06:02,990
然而，其中一些确实是高质量的。

944
01:06:02,990 --> 01:06:07,390
比如这张图片：你看，它有几近
完美的眼睛，完美的身材。

945
01:06:07,390 --> 01:06:10,390
这是一个非常好的质量图像。

946
01:06:10,390 --> 01:06:16,220
所以你的训练数据集和关键字，
你使用的提示，将百分百

947
01:06:16,220 --> 01:06:23,160
影响你将要得到的结果，
你真的需要

948
01:06:23,160 --> 01:06:25,529
根据你想要得到的东西来设计你的提示。

949
01:06:25,529 --> 01:06:30,120
现在让我向您展示一些用于
生成这些图像的提示。

950
01:06:30,120 --> 01:06:36,490
为此，我将转到 png 信息，好的，
然后我将拖放。

951
01:06:36,490 --> 01:06:41,240
例如，让我们先看一个 3d 类图像。

952
01:06:41,240 --> 01:06:51,500
好的，你看到这个使用了 blender、zbrush、
autodesk maya、unreal engine、colored，因为

953
01:06:51,500 --> 01:06:57,829
如果你想生成类似 3d 的图像，那么
你需要使用这些关键字。

954
01:06:57,829 --> 01:06:59,160
然后你可以将这些发送到。

955
01:06:59,160 --> 01:07:02,260
例如，让我们转到附加选项卡。

956
01:07:02,260 --> 01:07:08,270
在 extras 选项卡中，我可以放大此图像以
获得更大的尺寸。

957
01:07:08,270 --> 01:07:14,950
经过我的测试，我发现 R-ESRGAN
4x+ 效果最好。

958
01:07:14,950 --> 01:07:18,810
还有动漫版。

959
01:07:18,810 --> 01:07:25,850
另外，LDSR 工作得很好，但这
需要大量的 gpu 内存。

960
01:07:25,850 --> 01:07:31,480
因此，当我单击生成时，当您第一次
生成它时，它将下载

961
01:07:31,480 --> 01:07:35,740
R-ESRGAN 4x+ 所需的模型。

962
01:07:35,740 --> 01:07:41,220
你可以在这里看到，现在我们将看到放大的
图像。

963
01:07:41,220 --> 01:07:43,190
所以这是放大后的图像。

964
01:07:43,190 --> 01:07:48,760
高档的和正品的不会完全
一样，不过还是比较一下吧。

965
01:07:48,760 --> 01:07:54,420
让我们制作它们，不要放大，好吧。

966
01:07:54,420 --> 01:07:59,490
所以你看，这两者非常相似。

967
01:07:59,490 --> 01:08:02,690
质量有点损失。 让

968
01:08:02,690 --> 01:08:10,880
我们也尝试使用动漫版本。

969
01:08:10,880 --> 01:08:14,640
好的，现在我们有动漫版本。

970
01:08:14,640 --> 01:08:19,460
所以比方说，你想让你的图像
像动漫一样，然后你就可以使用它。

971
01:08:19,460 --> 01:08:23,060
这非常有用。

972
01:08:23,060 --> 01:08:26,000
您还可以升级整个文件夹。

973
01:08:26,000 --> 01:08:32,700
例如，我只需按住 Ctrl 键全选，
然后将它们拖放到此处。

974
01:08:32,700 --> 01:08:33,979
他们现在都在这里。

975
01:08:33,979 --> 01:08:37,329
现在我可以一次升级所有这些。

976
01:08:37,330 --> 01:08:38,330
让我展示。

977
01:08:38,330 --> 01:08:45,120
在操作过程中，您会看到它们
像这样平铺以生成更大

978
01:08:45,120 --> 01:08:47,770
尺寸的图像。

979
01:08:47,770 --> 01:08:52,790
升级额外选项卡的结果实际上
将在另一个文件夹中。

980
01:08:52,790 --> 01:08:58,979
当我点击它时，你会看到他们来到
这里，所有这些图像现在都被放大了。

981
01:08:58,979 --> 01:09:04,468
例如，让我们打开这个：实际上，这是一个皮克斯
风格的图像。

982
01:09:04,469 --> 01:09:13,719
好的，这是另一张皮克斯风格的图像，所以，
例如，这也是另一张皮克斯风格的

983
01:09:13,719 --> 01:09:17,220
图像，如您所见。

984
01:09:17,220 --> 01:09:23,779
我已经在 Google Colab 上训练了这些，
现在我将向您展示如何将

985
01:09:23,779 --> 01:09:31,988
模型上传到 Google Colab 并
在那里生成图像，而且速度可能比您的 gpu 快，

986
01:09:31,988 --> 01:09:40,108
因为 Google Colab gpu 非常强大，
能够处理很多 以

987
01:09:40,109 --> 01:09:41,729
并行方式一次处理图像。

988
01:09:41,729 --> 01:09:52,759
好吧，你看，所有这些都在升级，
好吧，嗯，让我们看一些这样的，

989
01:09:52,760 --> 01:10:02,410
正如你所看到的，好吧，好吧。

990
01:10:02,410 --> 01:10:06,700
现在我将展示另一件很酷的东西。

991
01:10:06,700 --> 01:10:13,270
通常你可能不会得到很好看的
眼睛或面部的一些错误，并且

992
01:10:13,270 --> 01:10:20,320
有一个很好的方法来改善眼睛或
面部的整体结构。

993
01:10:20,320 --> 01:10:26,830
它使用另一个 AI 模型，让我们尝试
改进此图像。

994
01:10:26,830 --> 01:10:31,360
通常，我的图像是非常好的眼睛。

995
01:10:31,360 --> 01:10:33,190
好的，测试一下。

996
01:10:33,190 --> 01:10:38,070
我只是不会高档，但我会
使用 GFPGAN。

997
01:10:38,070 --> 01:10:42,910
所以这个GFPGAN是一个改善眼睛的模型。

998
01:10:42,910 --> 01:10:43,910
让我们测试一下。

999
01:10:43,910 --> 01:10:48,190
当你第一次使用它时，它会下载
必要的模型。

1000
01:10:48,190 --> 01:10:50,290
好的，现在让我们比较一下结果。

1001
01:10:50,290 --> 01:10:53,770
这是原始图像，这是
固定图像。

1002
01:10:53,770 --> 01:10:59,140
现在让我们也申请高档，好吧。

1003
01:10:59,140 --> 01:11:07,600
好的，在应用 upscale 和
GFPGAN 之后，您会发现它现在

1004
01:11:07,600 --> 01:11:09,909
在质量正确性方面看起来好多了。

1005
01:11:09,909 --> 01:11:13,010
这将严重改善眼睛。

1006
01:11:13,010 --> 01:11:14,770
让我们像这样打开它们。

1007
01:11:14,770 --> 01:11:16,960
好吧，让我们放大。

1008
01:11:16,960 --> 01:11:22,340
所以你会看到差异是巨大的：
质量、样式要好得多。

1009
01:11:22,340 --> 01:11:26,540
您也可以将其批量应用于生成的图像
。

1010
01:11:26,540 --> 01:11:31,090
只需转到批处理并
从此处选择选项，它就会完成所有操作。

1011
01:11:31,090 --> 01:11:33,440
您也可以尝试这些其他选项。

1012
01:11:33,440 --> 01:11:39,320
我没有发现它们实际上很有用，
也没有对它们的描述。

1013
01:11:39,320 --> 01:11:44,130
好的，现在我将向您展示如何
从您设置的任何检查点继续训练

1014
01:11:44,130 --> 01:11:45,380
。

1015
01:11:45,380 --> 01:11:49,790
只需转到搜索检查点，您就会在
此处看到您保存的检查点，顺便说一句，

1016
01:11:49,790 --> 01:11:57,071
要将它们保存在保存中，您需要在检查点期间
保存时检查此生成器 ckpt 文件，

1017
01:11:57,071 --> 01:12:03,909
然后，如果您
从中生成新模型 检查点，你

1018
01:12:03,909 --> 01:12:08,360
基本上会从那个特定的
检查点继续训练。

1019
01:12:08,360 --> 01:12:16,790
现在我将向您展示如何
在 Google Colab 中直接使用这些 ckpt 文件。

1020
01:12:16,790 --> 01:12:22,360
如果您看过我之前关于将
自己变成令人惊叹的 ai 化身的视频，那么

1021
01:12:22,360 --> 01:12:30,360
本教程介绍了如何在 Google Colab 上进行训练，
并且在那里解释了

1022
01:12:30,360 --> 01:12:34,270
在 Google Colab 中使用您的 ckpt 文件的所有内容。

1023
01:12:34,270 --> 01:12:35,270
就是这么简单。

1024
01:12:35,270 --> 01:12:41,280
首先，我们将从
我们想要的检查点生成一个新模型。

1025
01:12:41,280 --> 01:12:47,460
假设我想使用步骤 1380 作为
检查点。

1026
01:12:47,460 --> 01:12:52,020
然后我将其命名为 Colab 图像。

1027
01:12:52,020 --> 01:12:54,380
好的，没有别的。

1028
01:12:54,380 --> 01:12:56,160
只需单击创建模型。

1029
01:12:56,160 --> 01:13:02,389
好的，它已经生成了一个，
为 Colab 图像和内部工作

1030
01:13:02,389 --> 01:13:10,480
目录生成了一个新模型，您只需要将其上传到
google google drive，然后给出它的

1031
01:13:10,480 --> 01:13:11,480
路径。

1032
01:13:11,480 --> 01:13:15,300
所以我会说，我的形象。

1033
01:13:15,300 --> 01:13:17,100
好的。

1034
01:13:17,100 --> 01:13:26,120
比方说，让我们也向其中添加我们的关键字，
让我们将它们移到这里，然后

1035
01:13:26,120 --> 01:13:34,730
像这样转到您的驱动器文件夹，您
正在运行 DreamBooth 或 Stable

1036
01:13:34,730 --> 01:13:41,830
Diffusion，然后将此目录拖放到
此处。

1037
01:13:41,830 --> 01:13:45,180
它将上传所有文件，如您
在此处所见。

1038
01:13:45,180 --> 01:13:52,159
上传完成后，我们需要
做的就是在

1039
01:13:52,159 --> 01:13:55,790
Google Colab notebook 的推理选项卡中更改模型路径。

1040
01:13:55,790 --> 01:13:59,989
这在教程的描述中有链接。

1041
01:13:59,989 --> 01:14:06,219
所以你需要像这样改变它：内容：
驱动我的驱动器，在这里我的驱动器图像

1042
01:14:06,219 --> 01:14:13,510
ohwx，这是我给的文件夹名称，
我正在上传到

1043
01:14:13,510 --> 01:14:15,540
我的谷歌驱动器的主文件夹。

1044
01:14:15,540 --> 01:14:21,630
然后，在 Google Colab 中，您将能够
立即使用经过训练的 ckpt 文件。

1045
01:14:21,630 --> 01:14:23,230
那么万一呢？

1046
01:14:23,230 --> 01:14:27,660
如果你想教另一张脸？

1047
01:14:27,660 --> 01:14:34,260
只需像这样生成一个新模型，这
一次，在概念文件夹中，

1048
01:14:34,260 --> 01:14:38,300
为您的新主题设置目录和分类目录
。

1049
01:14:38,300 --> 01:14:41,060
但是，请注意一些事情。

1050
01:14:41,060 --> 01:14:48,520
目前，我的模型使用 ohwx man
作为实例提示和 man photo 作为

1051
01:14:48,520 --> 01:14:50,050
类提示进行训练。

1052
01:14:50,050 --> 01:14:56,969
所以如果我要教另一个人，一个人，
一个男性，那么我必须选择另一个关键词，

1053
01:14:56,969 --> 01:15:06,300
例如 ske 或另一个罕见的关键词，
嗯，它也会把这个人教到模型中

1054
01:15:06,300 --> 01:15:07,300
。

1055
01:15:07,300 --> 01:15:09,440
所以我们将能够同时使用它们。

1056
01:15:09,440 --> 01:15:17,139
但是，您可能会得到不同的结果，
因为已经为

1057
01:15:17,139 --> 01:15:24,000
我自己的图像教授了 man 关键字，而当我介绍另一个
man 图像时，它们会变得混合。

1058
01:15:24,000 --> 01:15:27,931
所以这可能是个问题，但你可以
试试。

1059
01:15:27,931 --> 01:15:31,710
测试它，如果你生成足够的
图像，那么我想你会的。

1060
01:15:31,710 --> 01:15:34,050
你仍然可以得到很好的结果。

1061
01:15:34,050 --> 01:15:42,300
但是，如果你注入其他课程，
比如女性，那么问题应该不大

1062
01:15:42,300 --> 01:15:47,080
，你应该能够轻松地教授多个不同的
科目。

1063
01:15:47,080 --> 01:15:50,880
现在我将解释更高级的东西。

1064
01:15:50,880 --> 01:15:54,390
例如，目录、数据集目录。

1065
01:15:54,390 --> 01:16:02,550
好的，为了能够使用 [filewords]，你需要
有一个这样命名的训练数据集：

1066
01:16:02,550 --> 01:16:03,550
好的。

1067
01:16:03,550 --> 01:16:08,230
因此，对于每张图片，您还将拥有
一个同名的文本文件。

1068
01:16:08,230 --> 01:16:13,610
扩展名将是 txt，就像这样，并且，
您需要正确编写该文件的描述

1069
01:16:13,610 --> 01:16:16,620
。

1070
01:16:16,620 --> 01:16:20,660
有一个新的 AI 模型用于为图像添加字幕。

1071
01:16:20,660 --> 01:16:25,590
这还没有实现到 Automatic1111，
但我会的。

1072
01:16:25,590 --> 01:16:28,250
我会把这个的链接放到描述中。

1073
01:16:28,250 --> 01:16:31,120
您也可以在本地运行它。

1074
01:16:31,120 --> 01:16:38,020
如果您不知道如何在本地运行
，那么您需要

1075
01:16:38,020 --> 01:16:39,219
在我们的频道上观看我们的视频。

1076
01:16:39,219 --> 01:16:45,620
在此视频中，我将解释如何在本地
运行 HuggingFace 文件。

1077
01:16:45,620 --> 01:16:51,410
好的，我现在就使用在线演示，
因为它用得不多。

1078
01:16:51,410 --> 01:16:56,310
所以，第一张图片，我将拖放到
这里。

1079
01:16:56,310 --> 01:16:58,410
对于那个很抱歉。

1080
01:16:58,410 --> 01:17:01,150
好的，像这样：然后点击提交。

1081
01:17:01,150 --> 01:17:03,750
它将生成此图像的描述
。

1082
01:17:03,750 --> 01:17:08,380
你看，你应该使用
GIT large 生成的标题。

1083
01:17:08,380 --> 01:17:09,770
这是最好的。

1084
01:17:09,770 --> 01:17:13,550
一个黑发戴眼镜的男人正在微笑。

1085
01:17:13,550 --> 01:17:18,690
好的，让我们更改此文本文本。

1086
01:17:18,690 --> 01:17:20,139
文字描述，像这样。

1087
01:17:20,139 --> 01:17:27,150
然而，有一个关键问题：你
必须在这个描述中为这张图片设置你的类

1088
01:17:27,150 --> 01:17:28,150
。

1089
01:17:28,150 --> 01:17:31,210
所以我的班级是人，因此它在那里。

1090
01:17:31,210 --> 01:17:32,239
好吧，我们走吧。

1091
01:17:32,239 --> 01:17:33,239
然后。

1092
01:17:33,239 --> 01:17:40,560
这是我们要添加标题的另一张图片，
所以让我们提交它。

1093
01:17:40,560 --> 01:17:44,520
好的，然后这里是另一个图像描述
。

1094
01:17:44,520 --> 01:17:50,620
我们打开描述：一只长着长
胡子的猫看着镜头。

1095
01:17:50,620 --> 01:17:54,330
这是 cat 类，它
也在这里。

1096
01:17:54,330 --> 01:17:58,830
是的，正确，其余的也将用于狗
。

1097
01:17:58,830 --> 01:18:01,980
现在用于分类图像。

1098
01:18:01,980 --> 01:18:03,210
你需要做同样的事情。

1099
01:18:03,210 --> 01:18:08,890
生成分类时，还
需要有分类图像及其

1100
01:18:08,890 --> 01:18:10,960
描述。

1101
01:18:10,960 --> 01:18:16,430
比方说：这是我的分类图像
，它是用人的照片生成的。

1102
01:18:16,430 --> 01:18:23,560
因此，我需要像这样生成一个相同的文件
描述，并且在里面我需要

1103
01:18:23,560 --> 01:18:26,949
输入人的照片。

1104
01:18:26,949 --> 01:18:33,920
修复此选项卡后，让我告诉您
它是否已经修复，我不确定。

1105
01:18:33,920 --> 01:18:40,350
在这里，你看，我们已经生成了类图像
，当你使用该功能时，它将

1106
01:18:40,350 --> 01:18:44,580
能够：让我们试试吧，实际上没问题。

1107
01:18:44,580 --> 01:18:48,210
是的，没关系，好​​吧。

1108
01:18:48,210 --> 01:18:56,500
当我们在此处键入类提示符时
，我认为它会随之生成。

1109
01:18:56,500 --> 01:19:01,710
让我们试试看，好吧，它不起作用。

1110
01:19:01,710 --> 01:19:06,400
它说也许说好吧，它仍然无法正常工作。

1111
01:19:06,400 --> 01:19:10,130
当这变得可行时，您就可以轻松
生成它。

1112
01:19:10,130 --> 01:19:17,690
或者你需要生成
这样的描述：人的照片，它会生成

1113
01:19:17,690 --> 01:19:20,640
这样的图像，或者猫的照片或狗的照片。

1114
01:19:20,640 --> 01:19:27,500
所以这将是您的分类目录，
描述如下，这将是

1115
01:19:27,500 --> 01:19:29,971
您的分类目录，命名
如下。

1116
01:19:29,971 --> 01:19:37,429
通过这种方式，您可以
在一次运行中教授多个主题，

1117
01:19:37,429 --> 01:19:45,370
如果您提供更好的
描述并定义更多内容，您还可以提高培训质量。

1118
01:19:45,370 --> 01:19:53,130
顺便说一句，在定义时，您应该
在描述中指定您要

1119
01:19:53,130 --> 01:19:54,130
教授的主题。

1120
01:19:54,130 --> 01:19:58,610
如果你想教脸，那么你应该
主要描述脸。

1121
01:19:58,610 --> 01:20:05,080
好吧，还有一件事：好吧，一旦你
准备好了你的文件夹。

1122
01:20:05,080 --> 01:20:08,500
现在这里是这样做的方法。

1123
01:20:08,500 --> 01:20:14,250
首先，我们像往常一样定义数据集
目录。

1124
01:20:14,250 --> 01:20:16,850
好的，让我们设置它。

1125
01:20:16,850 --> 01:20:21,190
并且让我们也像这样设置分类目录
。

1126
01:20:21,190 --> 01:20:29,230
而在[filewords]中，我们需要使用定义
提示实例。

1127
01:20:29,230 --> 01:20:35,179
好的，这将用于定义它。

1128
01:20:35,179 --> 01:20:37,750
它必须是一个词。

1129
01:20:37,750 --> 01:20:41,880
因此，我正在输入 ohwx 和类
标记。

1130
01:20:41,880 --> 01:20:45,600
这也将是一个词。

1131
01:20:45,600 --> 01:20:55,250
顺便说一句，如果你这样使用，它实际上不会很精确
，class token。

1132
01:20:55,250 --> 01:21:02,600
但是，是的，看起来如果你教多个
不同的班级，那么你可能不会得到

1133
01:21:02,600 --> 01:21:08,540
很好的表现，例如，教一只
猫、一张脸、一只猫、一只狗和一个人，因为

1134
01:21:08,540 --> 01:21:12,340
它们与当前的设置相冲突。

1135
01:21:12,340 --> 01:21:17,660
所以使用三个概念更好，但让
我也向您解释一下。

1136
01:21:17,660 --> 01:21:18,770
所以这将是男人。

1137
01:21:18,770 --> 01:21:23,470
在提示中，您只需键入
[filewords] 和类提示。

1138
01:21:23,470 --> 01:21:30,000
您只需键入 [filewords] 并
留空以选择性地使用实例提示。

1139
01:21:30,000 --> 01:21:33,270
使用 [filewords] 将示例标题基于
实例图像。

1140
01:21:33,270 --> 01:21:40,090
您也可以使用 [filewords] 查看
它生成的内容。

1141
01:21:40,090 --> 01:21:47,810
这在 DreamBooth 扩展 wiki 的基础知识中称为混合位置
。

1142
01:21:47,810 --> 01:21:53,730
所以你看到
我在本教程中展示了 DreamBooth 常规培训。

1143
01:21:53,730 --> 01:21:55,580
然后是微调。

1144
01:21:55,580 --> 01:21:58,030
微调是大数据集的标准方法
。

1145
01:21:58,030 --> 01:22:00,510
仅使用图像的标题。

1146
01:22:00,510 --> 01:22:02,920
不使用 [filewords] 类图像。

1147
01:22:02,920 --> 01:22:07,590
这些导致模型不需要
实例令牌并对任何提示做出反应。

1148
01:22:07,590 --> 01:22:10,050
所以在这种情况下你是整体训练。

1149
01:22:10,050 --> 01:22:11,050
这意味着什么？

1150
01:22:11,050 --> 01:22:18,260
这意味着，比方说，在你的 [filewords] 中
你有汽车，有猫，有狗，

1151
01:22:18,260 --> 01:22:19,290
有男人。

1152
01:22:19,290 --> 01:22:22,969
你正在训练所有这些词。

1153
01:22:22,969 --> 01:22:28,449
这就是您看到的自定义模型
通常是如何训练的。

1154
01:22:28,449 --> 01:22:29,690
让我举个例子。

1155
01:22:29,690 --> 01:22:37,620
因此，例如，protogen x3.4 是一个自定义
模型，并且运行良好。

1156
01:22:37,620 --> 01:22:38,810
他们是如何训练它的？

1157
01:22:38,810 --> 01:22:41,580
他们可能通过微调对其进行了训练。

1158
01:22:41,580 --> 01:22:48,870
因此，在微调中，他们精确地准备了
每个训练图像的描述。

1159
01:22:48,870 --> 01:22:53,929
他们没有使用任何分类图像，
他们从整体上改变了

1160
01:22:53,929 --> 01:22:56,909
模型的底层上下文、数据和知识。

1161
01:22:56,909 --> 01:23:04,370
因此，当你现在使用 man 时，它会
根据他们新的微调数据

1162
01:23:04,370 --> 01:23:10,810
集或汽车或城堡或
你正在改进模型的任何东西生成人物图像的质量。

1163
01:23:10,810 --> 01:23:12,090
并且有混合动力。

1164
01:23:12,090 --> 01:23:15,840
好吧，实际上我说的是混合，但它会
是混合的。

1165
01:23:15,840 --> 01:23:20,860
混合，由于缺少或更好的术语，是
使用实例令牌结合 [filewords]

1166
01:23:20,860 --> 01:23:21,889
作为实例提示来实现的。

1167
01:23:21,889 --> 01:23:24,900
经过训练的数据集将链接到该实例
令牌。

1168
01:23:24,900 --> 01:23:29,820
这最大限度地减少了流血，但
在每个提示中都需要令牌，如您在此处所见。

1169
01:23:29,820 --> 01:23:37,710
所以你必须使用或 ohwx 法国斗牛犬
或 ohwx，无论你教过什么。

1170
01:23:37,710 --> 01:23:39,620
您还可以看到类标记是人。

1171
01:23:39,620 --> 01:23:45,530
因此，如果您使用带有 [filewords] 的混合模型，
如果您不进行微调而只教授

1172
01:23:45,530 --> 01:23:49,480
任何科目，我认为该科目应该是
同一个班级。

1173
01:23:49,480 --> 01:23:51,210
他们不能来自不同的班级。

1174
01:23:51,210 --> 01:23:59,520
所以你可以在一次运行中教多个人
，也许 10 个人，只需要提供

1175
01:23:59,520 --> 01:24:03,179
正确的 [filewords] 和他们的描述。

1176
01:24:03,179 --> 01:24:09,540
因此，对于您需要添加的这个人，
假设是一个人 personA。

1177
01:24:09,540 --> 01:24:11,500
好的，这将定义 personA。

1178
01:24:11,500 --> 01:24:16,110
对于 b 人，您需要添加 personB，
对于 c 人，您需要添加 personC。

1179
01:24:16,110 --> 01:24:24,990
但是您不会添加到此描述中：
您不会添加此实例令牌。

1180
01:24:24,990 --> 01:24:30,679
好的，您不需要将实例标记
键入 [filewords]、

1181
01:24:30,679 --> 01:24:37,560
训练图像的描述或
分类图像的描述中。

1182
01:24:37,560 --> 01:24:39,220
好的，这很重要。

1183
01:24:39,220 --> 01:24:46,100
好的，现在我将向您展示如何理解
内存不足错误。

1184
01:24:46,100 --> 01:24:47,100
所以很容易。

1185
01:24:47,100 --> 01:24:50,980
我只是要为我们现有的
数据集加载设置。

1186
01:24:50,980 --> 01:24:52,369
你看，我有一个错误。

1187
01:24:52,369 --> 01:24:54,520
所以看起来我在 cmd 中有错误。

1188
01:24:54,520 --> 01:24:56,020
我只需要重新启动。

1189
01:24:56,020 --> 01:25:03,370
好的，我确实重新启动并在设置中，如果
我设置使用 EMA。

1190
01:25:03,370 --> 01:25:08,429
所以实际上这提高了我们的结果质量，
但它会花费更多的内存。

1191
01:25:08,429 --> 01:25:14,679
然后我只需单击训练，让我们看看
我们将如何摆脱内存不足错误。

1192
01:25:14,679 --> 01:25:18,300
好的，我们得到了我们的错误。

1193
01:25:18,300 --> 01:25:22,050
让我向您展示如何理解内存不足
错误。

1194
01:25:22,050 --> 01:25:24,790
您将看到运行时 CUDA 内存不足。

1195
01:25:24,790 --> 01:25:28,890
如果您看到此错误，则所有其他消息
都不重要。

1196
01:25:28,890 --> 01:25:34,750
这意味着在
您尝试训练的当前设置下，您的图形

1197
01:25:34,750 --> 01:25:38,290
卡不够用，您需要减少
ram 的使用。

1198
01:25:38,290 --> 01:25:43,120
现在让我向您展示
如何减少 ram 使用的所有设置。

1199
01:25:43,120 --> 01:25:48,980
好吧，为了最小化 ram 使用，你需要
选择 LoRA 和 LoRA。

1200
01:25:48,980 --> 01:25:52,820
只有一点点不同。

1201
01:25:52,820 --> 01:26:00,210
只有当您尝试
从生成的 LoRA 文件中进行推理并生成新图像时，情况才会有所不同

1202
01:26:00,210 --> 01:26:01,210
。

1203
01:26:01,210 --> 01:26:06,780
当您观看此视频时，您会了解到
，好吧，LoRA 将显着减少

1204
01:26:06,780 --> 01:26:08,170
ram 的使用。

1205
01:26:08,170 --> 01:26:12,060
除此之外，请始终确保您的
批量大小和梯度累积步骤

1206
01:26:12,060 --> 01:26:20,500
是一个，除此之外，
您需要在高级选项卡中选择使用 8 位 adam 并选择

1207
01:26:20,500 --> 01:26:23,590
bf16 并选择 xformers。

1208
01:26:23,590 --> 01:26:31,040
因此，要使 xformers 能够，您需要将
起始参数设置为 xformers 和

1209
01:26:31,040 --> 01:26:33,300
minus minus no half。

1210
01:26:33,300 --> 01:26:35,540
这些将允许您使用它。

1211
01:26:35,540 --> 01:26:36,540
缓存潜伏。

1212
01:26:36,540 --> 01:26:37,880
其实就是这个。

1213
01:26:37,880 --> 01:26:39,699
这还不清楚。

1214
01:26:39,699 --> 01:26:42,830
您应该同时尝试选中和未选中。

1215
01:26:42,830 --> 01:26:49,179
因为有人说这个增加，有人
说这个减少。

1216
01:26:49,179 --> 01:26:50,270
文本编码器训练的步长比也是如此。

1217
01:26:50,270 --> 01:26:54,900
这应该为零，因为这会提高
质量但也会降低，还会增加

1218
01:26:54,900 --> 01:26:56,900
vram 使用率。

1219
01:26:56,900 --> 01:27:02,040
除了这些，
您无能为力。

1220
01:27:02,040 --> 01:27:04,610
这些是最低的。

1221
01:27:04,610 --> 01:27:12,550
此外，您需要取消选中此复选框，并且
需要选中此复选框。

1222
01:27:12,550 --> 01:27:18,550
因此，当您选中此复选框时，它会增加
您的 vram 使用量，但当您选中此复选框时，

1223
01:27:18,550 --> 01:27:21,490
它会减少您的 vram 使用量。

1224
01:27:21,490 --> 01:27:26,010
实际上，实际上，设置写
在DreamBooth wiki扩展的故障排除部分

1225
01:27:26,010 --> 01:27:32,300
，在OOM选项卡中，
还有overtraining等。

1226
01:27:32,300 --> 01:27:37,440
实际上，过度训练仍在进行中，
我已经向您展示了如何

1227
01:27:37,440 --> 01:27:39,469
理解过度训练。

1228
01:27:39,469 --> 01:27:45,310
我要向您展示的另一件很酷的事情
是预处理您的图像。

1229
01:27:45,310 --> 01:27:52,540
因此，通过预处理图像，您可以轻松地
为训练

1230
01:27:52,540 --> 01:27:55,940
图像和分类图像生成描述。

1231
01:27:55,940 --> 01:28:00,860
当然他们不会很准确，所以
让我告诉你。

1232
01:28:00,860 --> 01:28:09,850
我选择我最好的 db 512 作为源目录，
描述目录将相同。

1233
01:28:09,850 --> 01:28:16,330
所以在这里你甚至可以定义它们的目标
分辨率，改变它们，但我更喜欢手动

1234
01:28:16,330 --> 01:28:19,110
改变它们和字幕。

1235
01:28:19,110 --> 01:28:26,640
所以对于字幕，我只是选择
忽略，所以它会生成新的字幕，

1236
01:28:26,640 --> 01:28:29,500
我将使用 deepbooru 来制作字幕。

1237
01:28:29,500 --> 01:28:35,800
您还可以生成翻转副本超大
图像、拆分、自动焦点裁剪。

1238
01:28:35,800 --> 01:28:41,080
假设您有数万张
图片，那么这些选项将对

1239
01:28:41,080 --> 01:28:42,450
您非常有用。

1240
01:28:42,450 --> 01:28:47,250
但是，如果你只打算训练你的
脸，那么你应该手动准备你的

1241
01:28:47,250 --> 01:28:53,170
训练数据集是最好的，然后我
将为它们生成字幕。

1242
01:28:53,170 --> 01:28:54,910
我只是要点击预处理。

1243
01:28:54,910 --> 01:29:03,000
它不应该改变宽度和高度，因为
它们已经是 512 像素并且它正在下载

1244
01:29:03,000 --> 01:29:04,530
deepbooru 用于字幕。

1245
01:29:04,530 --> 01:29:09,810
这是另一个模型，正如我
在这里向您展示的那样。

1246
01:29:09,810 --> 01:29:15,750
deepbooru 不如 git large 生成的标题好
，但它仍然有用，

1247
01:29:15,750 --> 01:29:17,310
稍后我们将看到。

1248
01:29:17,310 --> 01:29:19,230
好的，它抛出了一个错误。

1249
01:29:19,230 --> 01:29:22,960
表示指定为源目录
和目标目录的同一目录。

1250
01:29:22,960 --> 01:29:25,570
显然，这是不允许的。

1251
01:29:25,570 --> 01:29:28,610
实际上，他们不允许是件好事
。

1252
01:29:28,610 --> 01:29:36,230
所以我只是将其更改为已处理，
这样您就不会覆盖原始图像

1253
01:29:36,230 --> 01:29:39,260
，只需点击预处理即可。

1254
01:29:39,260 --> 01:29:45,690
好的，模型只下载一次，
所有图像都经过预处理。

1255
01:29:45,690 --> 01:29:48,730
因此，让我们检查一下预处理后的图像。

1256
01:29:48,730 --> 01:29:52,030
好的，您会看到带有描述的相同图像。

1257
01:29:52,030 --> 01:29:53,240
让我们看看描述。

1258
01:29:53,240 --> 01:29:58,530
所以描述是一个：男孩，黑发，胡子，灰色裤子，
夹克，长袖，

1259
01:29:58,530 --> 01:30:05,260
男性焦点裤，逼真的单人亚稳定
运动夹克和track it运动裤。

1260
01:30:05,260 --> 01:30:07,119
所以这是一个很好的描述。

1261
01:30:07,119 --> 01:30:10,520
您也可以手动修改它们。

1262
01:30:10,520 --> 01:30:17,150
让我们也修改我们的分类图像，
这样，它将生成

1263
01:30:17,150 --> 01:30:18,840
分类图像的所有描述。

1264
01:30:18,840 --> 01:30:22,949
顺便说一句，正如我所说，这在
您使用 [filewords] 时很有用。

1265
01:30:22,949 --> 01:30:26,440
如果您不使用 [filewords]，那么这些将
不会被使用。

1266
01:30:26,440 --> 01:30:32,119
这也很有用，非常有用，如果你使用
超网络或嵌入，我

1267
01:30:32,119 --> 01:30:35,250
也希望制作一个关于嵌入的视频。

1268
01:30:35,250 --> 01:30:39,179
超网络不是很好，但嵌入
确实非常好。

1269
01:30:39,179 --> 01:30:45,010
好的，让我们预处理我们的分类
文件夹。

1270
01:30:45,010 --> 01:30:47,340
所以预处理在 train 选项卡中。

1271
01:30:47,340 --> 01:30:50,230
这是 Automatic1111 的一项功能。

1272
01:30:50,230 --> 01:30:53,409
好的，并对其进行预处理。

1273
01:30:53,409 --> 01:30:57,020
它也非常快。

1274
01:30:57,020 --> 01:31:00,730
所以这对字幕非常有用。

1275
01:31:00,730 --> 01:31:07,530
而且，如果你的图像没有被正确
裁剪，并且你有成千上万的

1276
01:31:07,530 --> 01:31:10,091
图像，就像我说的那样，那将花费大量时间。

1277
01:31:10,091 --> 01:31:12,430
你可以只用这个。

1278
01:31:12,430 --> 01:31:17,239
作为初学者，您还可以使用它来
简化您的工作并查看结果及其

1279
01:31:17,239 --> 01:31:18,239
执行情况。

1280
01:31:18,239 --> 01:31:23,460
假设您选择了数百张
自己的照片，但不想花时间。

1281
01:31:23,460 --> 01:31:31,810
然后你可以像这样预处理图像并
尝试，尝试，训练，尝试对它们进行训练

1282
01:31:31,810 --> 01:31:32,810
并查看结果。

1283
01:31:32,810 --> 01:31:37,929
如果你能得到好的结果，那为什么不
花更多的时间，更多的时间呢？

1284
01:31:37,929 --> 01:31:43,520
但是如果你想得到完美的结果，那么
你需要手动裁剪你的图像并

1285
01:31:43,520 --> 01:31:47,639
设置你的描述。

1286
01:31:47,639 --> 01:31:49,560
现在让我们看看预处理。

1287
01:31:49,560 --> 01:31:51,840
每个图像都有描述。

1288
01:31:51,840 --> 01:31:52,840
让我们看看它们。

1289
01:31:52,840 --> 01:31:59,570
好吧，比如说，它把这个男人定义
为女孩，这是非常不正确的，也是

1290
01:31:59,570 --> 01:32:01,050
3d的亚洲黑衬衫。

1291
01:32:01,050 --> 01:32:06,219
好的，如您所见，这是一个完全错误的描述
。

1292
01:32:06,219 --> 01:32:07,909
彻底失败了。

1293
01:32:07,909 --> 01:32:12,040
现在让我们将其与
我展示的大型 git 进行比较。

1294
01:32:12,040 --> 01:32:18,280
好的，我想知道我们
将使用大型 git 获得什么样的结果，所以我只是要

1295
01:32:18,280 --> 01:32:21,389
拖放。

1296
01:32:21,389 --> 01:32:27,659
顺便说一下，正如我所说，我建议将此
模型添加到 Automatic1111 以获得更好的

1297
01:32:27,659 --> 01:32:32,510
结果，并且大型 git 生成了一个
留着胡子的人的肖像。

1298
01:32:32,510 --> 01:32:41,350
是的，
与这个无用的描述相比，绝对正确，如您

1299
01:32:41,350 --> 01:32:42,350
所见。

1300
01:32:42,350 --> 01:32:48,320
好的，最后，我建议你看看
ELI5 培训。

1301
01:32:48,320 --> 01:32:55,869
所以这是由有经验的人更新的
，例如，在 [filewords] 中，

1302
01:32:55,869 --> 01:33:01,369
他们说他们给出了一个
例子，令牌 alexa 很糟糕，因为

1303
01:33:01,369 --> 01:33:06,760
alexa 的基础数据很好，很难
覆盖它。

1304
01:33:06,760 --> 01:33:12,700
这也很糟糕，因为它被拆
分成这样：ohwx，太好了。

1305
01:33:12,700 --> 01:33:15,530
类令牌也很重要。

1306
01:33:15,530 --> 01:33:19,400
我已经体验过它们，但您也可以
查看这些页面。

1307
01:33:19,400 --> 01:33:24,170
我会将这些页面的链接放入
描述中。

1308
01:33:24,170 --> 01:33:26,710
现在我将向您展示另一件非常酷的
东西。

1309
01:33:26,710 --> 01:33:33,710
你看，这个 Protogen x3.4 是一个自定义模型，
使用多个

1310
01:33:33,710 --> 01:33:40,130
模型生成，大量训练，你看，如果
你把你的脸或主体训练到这个模型中，

1311
01:33:40,130 --> 01:33:43,119
它不会产生好的结果。

1312
01:33:43,119 --> 01:33:48,389
因为基础数据已经发生了显着
变化。

1313
01:33:48,389 --> 01:33:53,270
那么我们如何才能将我们的脸注入到这个模型中呢？

1314
01:33:53,270 --> 01:33:56,230
有一种方法可以做到这一点，现在我将向
您展示。

1315
01:33:56,230 --> 01:34:05,020
我们进入检查点合并，在
主要模型中，我们选择目标

1316
01:34:05,020 --> 01:34:09,090
模型，即 Protogen x 3.4。

1317
01:34:09,090 --> 01:34:16,970
二级模型将是我们
正在使用的训练它的模型，它将是

1318
01:34:16,970 --> 01:34:19,140
这个：ohwx 1308。

1319
01:34:19,140 --> 01:34:21,230
还有三级模型。

1320
01:34:21,230 --> 01:34:24,320
所以第三个模型将是 1.5 版。

1321
01:34:24,320 --> 01:34:29,160
这是模型，这是
我们模型的基础模型，我们要做的

1322
01:34:29,160 --> 01:34:37,310
是从
基础模型中提取图像，并将图像应用到

1323
01:34:37,310 --> 01:34:39,850
新的目标模型中。

1324
01:34:39,850 --> 01:34:49,520
我们给它起个名字：ohwx，protogen okay，
3.4，权重设置为0.75。

1325
01:34:49,520 --> 01:34:50,520
这是 75%。

1326
01:34:50,520 --> 01:34:53,619
你可能会问：你是怎么得出这个
值的？

1327
01:34:53,619 --> 01:35:00,050
我问了社区，根据
社区的经验，75% 是一个很好的

1328
01:35:00,050 --> 01:35:01,050
点。

1329
01:35:01,050 --> 01:35:03,060
当然，您可以尝试多个不同的
点。

1330
01:35:03,060 --> 01:35:08,010
您可以尝试不同的检查点，
看看您的表现如何。

1331
01:35:08,010 --> 01:35:10,410
另外，单击添加差异。

1332
01:35:10,410 --> 01:35:16,230
因此，这将从
我们的基础模型中提取我们的面部信息，并将我们的

1333
01:35:16,230 --> 01:35:25,690
面部信息注入到我们的新目标模型中，而
不会破坏底层上下文

1334
01:35:25,690 --> 01:35:26,690
信息。

1335
01:35:26,690 --> 01:35:31,570
我们将生成 ckpt 添加差异，
然后单击运行。

1336
01:35:31,570 --> 01:35:36,750
在 cmd 窗口中，您将看到
如下消息：和检查点已保存，然后在

1337
01:35:36,750 --> 01:35:42,940
此处刷新并转到我们的新模型，即
ohwx protogen。

1338
01:35:42,940 --> 01:35:51,350
现在我们可以像
往常一样使用原模型和我们的脸来制作图像。

1339
01:35:51,350 --> 01:35:58,219
好的，大家，我做了一些测试，
结果非常棒。

1340
01:35:58,219 --> 01:36:03,290
所以你看，这些是
我从结果中选择的一些图像。

1341
01:36:03,290 --> 01:36:05,469
让我给你看点东西。

1342
01:36:05,469 --> 01:36:12,500
所以你看，这是由 protogen 生成的，
这是我的原始真实图像。

1343
01:36:12,500 --> 01:36:14,600
这是生成的图像。

1344
01:36:14,600 --> 01:36:15,670
你看质量。

1345
01:36:15,670 --> 01:36:17,830
这真是太神奇了。

1346
01:36:17,830 --> 01:36:20,290
我做了什么样的测试。

1347
01:36:20,290 --> 01:36:29,449
为了测试，我使用了 x/y 图，我
输入了不同的 x 值作为 CFG，我

1348
01:36:29,449 --> 01:36:32,409
输入了提示 sr 作为权重。

1349
01:36:32,409 --> 01:36:33,860
那我是怎么做到的？

1350
01:36:33,860 --> 01:36:41,630
所以你看到了 ohwx 人，然后我们
在这里输入一个权重，正确地赋予

1351
01:36:41,630 --> 01:36:42,630
它重要性。

1352
01:36:42,630 --> 01:36:49,010
所以我在这里输入了一个关键字 change weight
并且我在提示 sr 中将它用作 change weight here

1353
01:36:49,010 --> 01:36:50,150
。

1354
01:36:50,150 --> 01:36:59,420
因此，您将 Automatic1111 ui 应用程序
更改为我的重量并测试了不同的

1355
01:36:59,420 --> 01:37:00,420
重量。

1356
01:37:00,420 --> 01:37:09,520
现在我可以看到这个生成的
部分特定图像的属性，以查看

1357
01:37:09,520 --> 01:37:10,520
使用的值是什么。

1358
01:37:10,520 --> 01:37:14,179
然后，基于此，我可以生成任何
我想要的东西。

1359
01:37:14,179 --> 01:37:20,810
所以使用的权重是 1.4，cfg 比例
是 8。

1360
01:37:20,810 --> 01:37:28,449
所以通过使用 1.4 和 cfg 比例 8，我可以生成
质量更高的图像。

1361
01:37:28,449 --> 01:37:35,580
所以这两个参数将适用于我的
合并模型。

1362
01:37:35,580 --> 01:37:39,869
顺便说一句，我也用过别的东西。

1363
01:37:39,869 --> 01:37:46,380
你看，有一个模型散列和那个散列，
这里写的散列，也显示在这里。

1364
01:37:46,380 --> 01:37:53,670
这个95意味着我又生成了一个
checkpoint，但是这次我使用了95%的

1365
01:37:53,670 --> 01:37:54,670
权重。

1366
01:37:54,670 --> 01:37:57,520
这对我来说效果更好。

1367
01:37:57,520 --> 01:38:03,889
所以一开始你可以从 75 开始，
如果你没有得到好的图像，那么

1368
01:38:03,889 --> 01:38:11,400
你可以增加它并进行不同的模型
合并，然后对它们进行测试。

1369
01:38:11,400 --> 01:38:17,360
所以这就是如何测试和找出
模型的良好工作参数

1370
01:38:17,360 --> 01:38:22,680
，然后使用这些参数
根据需要生成更多风格化图像的方法。

1371
01:38:22,680 --> 01:38:25,070
但结果简直太棒了。

1372
01:38:25,070 --> 01:38:30,969
您不能仅
在默认的稳定扩散模型上如此轻松地获得这些结果。

1373
01:38:30,969 --> 01:38:37,740
因此，您可以将经过训练的模型、经过训练的
面部注入任何自定义模型，并根据

1374
01:38:37,740 --> 01:38:42,159
需要生成漂亮的图像。

1375
01:38:42,159 --> 01:38:45,340
因此，让我们也升级此图像。

1376
01:38:45,340 --> 01:38:51,900
为此，我将把它发送给
临时演员，我将使用 R-ESRGAN

1377
01:38:51,900 --> 01:38:53,130
4x+ 对其进行升级。

1378
01:38:53,130 --> 01:38:56,739
结果是：它很漂亮。 让

1379
01:38:56,739 --> 01:39:02,340
我们也应用 GFPGAN 来获得更好的人脸
质量。

1380
01:39:02,340 --> 01:39:07,110
好的，现在，如你所见，惊人的
质量，惊人的图像。

1381
01:39:07,110 --> 01:39:13,190
如您所见，这里只有一件人工制品
。 所以如果我生成这样的图像，

1382
01:39:13,190 --> 01:39:15,600
我也可以摆脱这个人工制品。

1383
01:39:15,600 --> 01:39:19,230
我想我已经涵盖了几乎所有内容。

1384
01:39:19,230 --> 01:39:22,889
正如我一开始所说，只需加入我们的
Discord 频道即可。

1385
01:39:22,889 --> 01:39:29,700
从我们的“关于”页面以及此处，
您将看到该链接。

1386
01:39:29,700 --> 01:39:35,590
只需单击官方不和谐。 也请
分享、点赞、订阅，如果您支持

1387
01:39:35,590 --> 01:39:39,810
我们的 patreon，我将不胜感激。

1388
01:39:39,810 --> 01:39:42,040
目前我们有三位赞助人。

1389
01:39:42,040 --> 01:39:48,159
我想我非常感谢他们成为
我们的赞助人，支持我们的工作。 如您所见，

1390
01:39:48,159 --> 01:39:53,369
您也可以从这里加入我们的频道并支持
我们。

1391
01:39:53,369 --> 01:39:56,260
感谢您的每一点支持。

1392
01:39:56,260 --> 01:39:59,290
希望在另一个视频中见到你。

1393
01:39:59,290 --> 01:40:02,530
请发表评论并提出问题。

1394
01:40:02,530 --> 01:40:07,340
询问您想作为新
um 教程查看的主题。

1395
01:40:07,340 --> 01:40:09,090
非常感谢。

1396
01:40:09,090 --> 01:40:09,999
希望以后再见。

